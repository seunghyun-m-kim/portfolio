{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Warehouse and ETL Pipeline with AWS Redshift and Postgres\n",
    "## Project: Data Engineering Capstone\n",
    "\n",
    "This project was completed as part of Udacity's Data Engineering Nanodegree. Data set and prompt provided by [2011â€“2020 Udacity, Inc.](https://www.udacity.com), used under [CC BY](https://creativecommons.org/licenses/by-nc-nd/3.0/).\n",
    "\n",
    "#### Project Summary\n",
    "In this project, we will set up a data warehouse for the US traffic fatality records, specifically data on fatal car crashes that occurred during the years 2016-2018.  \n",
    "\n",
    "The project follows the following steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "A data warehouse will be set up on the AWS Redshift cluster. Raw template traffic and location data will first be staged in AWS S3, and ETL will be performed via Redshift and Postgres to load a star schema of tables for further analysis. Three sets of annual traffic data (2016, 2017, 2018) will be worked on to create three sets (2016, 2017, 2018) of product tables.  \n",
    "#### Describe and Gather Data \n",
    "A set of fatal traffic crash data (csv format) will be gathered from the National Highway Traffic Safety Administration's (NHTSA) Fatality Analysis Reporting System (FARS) [database](ftp://ftp.nhtsa.dot.gov/fars/), which will include the following:\n",
    "\n",
    "* accident: General crash data.\n",
    "* drimpair: Impairment of drivers during the crash. \n",
    "* nmimpair: Impairment of non-motorists during the crash.\n",
    "* person: General motorist and non-motorist data.\n",
    "* vehicle: General vehicle data as well as driver and precrash data.\n",
    "\n",
    "Also, location data (xlsx format) will be gathered from the U.S. General Services Administration's (GSA) Geographic Locator Codes (GLCs) [database](https://www.gsa.gov/reference/geographic-locator-codes/glcs-for-the-us-and-us-territories):\n",
    "\n",
    "* glc: US State, City, and County codes and locations referred in the above crash data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data\n",
    "We will first explore the data by opening each file (stored in the repository folder called \"data\") and checking the first few rows. For this quick view, we will just check the 2018 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>ST_CASE</th>\n",
       "      <th>VE_TOTAL</th>\n",
       "      <th>VE_FORMS</th>\n",
       "      <th>PVH_INVL</th>\n",
       "      <th>PEDS</th>\n",
       "      <th>PERNOTMVIT</th>\n",
       "      <th>PERMVIT</th>\n",
       "      <th>PERSONS</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>CITY</th>\n",
       "      <th>DAY</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>DAY_WEEK</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MINUTE</th>\n",
       "      <th>NHS</th>\n",
       "      <th>RUR_URB</th>\n",
       "      <th>FUNC_SYS</th>\n",
       "      <th>RD_OWNER</th>\n",
       "      <th>ROUTE</th>\n",
       "      <th>TWAY_ID</th>\n",
       "      <th>TWAY_ID2</th>\n",
       "      <th>MILEPT</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUD</th>\n",
       "      <th>SP_JUR</th>\n",
       "      <th>HARM_EV</th>\n",
       "      <th>MAN_COLL</th>\n",
       "      <th>RELJCT1</th>\n",
       "      <th>RELJCT2</th>\n",
       "      <th>TYP_INT</th>\n",
       "      <th>WRK_ZONE</th>\n",
       "      <th>REL_ROAD</th>\n",
       "      <th>LGT_COND</th>\n",
       "      <th>WEATHER1</th>\n",
       "      <th>WEATHER2</th>\n",
       "      <th>WEATHER</th>\n",
       "      <th>SCH_BUS</th>\n",
       "      <th>RAIL</th>\n",
       "      <th>NOT_HOUR</th>\n",
       "      <th>NOT_MIN</th>\n",
       "      <th>ARR_HOUR</th>\n",
       "      <th>ARR_MIN</th>\n",
       "      <th>HOSP_HR</th>\n",
       "      <th>HOSP_MN</th>\n",
       "      <th>CF1</th>\n",
       "      <th>CF2</th>\n",
       "      <th>CF3</th>\n",
       "      <th>FATALS</th>\n",
       "      <th>DRUNK_DR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>1870</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1676</td>\n",
       "      <td>33.591331</td>\n",
       "      <td>-86.1319</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0000000</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>1780</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I-22</td>\n",
       "      <td>CALUMET RD</td>\n",
       "      <td>1621</td>\n",
       "      <td>33.809186</td>\n",
       "      <td>-87.2898</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0000000</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10003</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I-65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2028</td>\n",
       "      <td>32.767736</td>\n",
       "      <td>-86.5640</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0000000</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I-65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>460</td>\n",
       "      <td>31.027806</td>\n",
       "      <td>-87.6432</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0000000</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10005</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>330</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I-459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>33.332103</td>\n",
       "      <td>-86.9938</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0000000</td>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATE  ST_CASE  VE_TOTAL  VE_FORMS  PVH_INVL  PEDS  PERNOTMVIT  PERMVIT  \\\n",
       "0      1    10001         2         1         1     0           0        1   \n",
       "1      1    10002         1         1         0     0           0        2   \n",
       "2      1    10003         2         2         0     0           0        2   \n",
       "3      1    10004         1         1         0     0           0        2   \n",
       "4      1    10005         2         2         0     0           0        2   \n",
       "\n",
       "   PERSONS  COUNTY  CITY  DAY  MONTH  YEAR  DAY_WEEK  HOUR  MINUTE  NHS  \\\n",
       "0        1     121  1870    5      1  2018         6     6       0    1   \n",
       "1        2     127  1780    8      1  2018         2     0      48    1   \n",
       "2        2      21     0    8      1  2018         2    22      50    1   \n",
       "3        2       3     0    9      1  2018         3    13       2    1   \n",
       "4        2      73   330   19      1  2018         6     7       9    1   \n",
       "\n",
       "   RUR_URB  FUNC_SYS  RD_OWNER  ROUTE TWAY_ID    TWAY_ID2  MILEPT   LATITUDE  \\\n",
       "0        1         1         1      1    I-20         NaN    1676  33.591331   \n",
       "1        2         1         1      1    I-22  CALUMET RD    1621  33.809186   \n",
       "2        1         1         1      1    I-65         NaN    2028  32.767736   \n",
       "3        1         1         1      1    I-65         NaN     460  31.027806   \n",
       "4        2         1         1      1   I-459         NaN      17  33.332103   \n",
       "\n",
       "   LONGITUD  SP_JUR  HARM_EV  MAN_COLL  RELJCT1  RELJCT2  TYP_INT  WRK_ZONE  \\\n",
       "0  -86.1319       0       14         0        0        1        1         0   \n",
       "1  -87.2898       0       38         0        1       19        1         0   \n",
       "2  -86.5640       0       24         0        0        1        1         1   \n",
       "3  -87.6432       0       24         0        0        1        1         0   \n",
       "4  -86.9938       0       12         1        0        1        1         0   \n",
       "\n",
       "   REL_ROAD  LGT_COND  WEATHER1  WEATHER2  WEATHER  SCH_BUS     RAIL  \\\n",
       "0         2         4         1         0        1        0  0000000   \n",
       "1         3         2         2         0        2        0  0000000   \n",
       "2         4         2        10         0       10        0  0000000   \n",
       "3         4         1        10         0       10        0  0000000   \n",
       "4         1         1         1         0        1        0  0000000   \n",
       "\n",
       "   NOT_HOUR  NOT_MIN  ARR_HOUR  ARR_MIN  HOSP_HR  HOSP_MN  CF1  CF2  CF3  \\\n",
       "0         6       99         6       15       88       88    0    0    0   \n",
       "1         0       99         0       59       88       88   20    0    0   \n",
       "2        99       99        23       10       99       99    0    0    0   \n",
       "3        13       99        13       14       88       88    0    0    0   \n",
       "4         7       99         7       28       88       88    0    0    0   \n",
       "\n",
       "   FATALS  DRUNK_DR  \n",
       "0       1         0  \n",
       "1       2         0  \n",
       "2       1         0  \n",
       "3       1         0  \n",
       "4       1         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accident\n",
    "pd.read_csv(\"data/accident/2018/accident2018.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>ST_CASE</th>\n",
       "      <th>VEH_NO</th>\n",
       "      <th>DRIMPAIR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10002</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10003</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10003</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10004</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATE  ST_CASE  VEH_NO  DRIMPAIR\n",
       "0      1    10001       1         0\n",
       "1      1    10002       1        99\n",
       "2      1    10003       1        99\n",
       "3      1    10003       2         0\n",
       "4      1    10004       1        99"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drimpair\n",
    "pd.read_csv(\"data/drimpair/2018/drimpair2018.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>ST_CASE</th>\n",
       "      <th>VEH_NO</th>\n",
       "      <th>PER_NO</th>\n",
       "      <th>NMIMPAIR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATE  ST_CASE  VEH_NO  PER_NO  NMIMPAIR\n",
       "0      1    10006       0       1         0\n",
       "1      1    10007       0       1        99\n",
       "2      1    10008       0       1        99\n",
       "3      1    10010       0       1        99\n",
       "4      1    10017       0       1        99"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nmimpair\n",
    "pd.read_csv(\"data/nmimpair/2018/nmimpair2018.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>ST_CASE</th>\n",
       "      <th>VE_FORMS</th>\n",
       "      <th>VEH_NO</th>\n",
       "      <th>PER_NO</th>\n",
       "      <th>STR_VEH</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>DAY</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MINUTE</th>\n",
       "      <th>RUR_URB</th>\n",
       "      <th>FUNC_SYS</th>\n",
       "      <th>HARM_EV</th>\n",
       "      <th>MAN_COLL</th>\n",
       "      <th>SCH_BUS</th>\n",
       "      <th>MAKE</th>\n",
       "      <th>MAK_MOD</th>\n",
       "      <th>BODY_TYP</th>\n",
       "      <th>MOD_YEAR</th>\n",
       "      <th>TOW_VEH</th>\n",
       "      <th>SPEC_USE</th>\n",
       "      <th>EMER_USE</th>\n",
       "      <th>ROLLOVER</th>\n",
       "      <th>IMPACT1</th>\n",
       "      <th>FIRE_EXP</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PER_TYP</th>\n",
       "      <th>INJ_SEV</th>\n",
       "      <th>SEAT_POS</th>\n",
       "      <th>REST_USE</th>\n",
       "      <th>REST_MIS</th>\n",
       "      <th>AIR_BAG</th>\n",
       "      <th>EJECTION</th>\n",
       "      <th>EJ_PATH</th>\n",
       "      <th>EXTRICAT</th>\n",
       "      <th>DRINKING</th>\n",
       "      <th>ALC_DET</th>\n",
       "      <th>ALC_STATUS</th>\n",
       "      <th>ATST_TYP</th>\n",
       "      <th>ALC_RES</th>\n",
       "      <th>DRUGS</th>\n",
       "      <th>DRUG_DET</th>\n",
       "      <th>DSTATUS</th>\n",
       "      <th>HOSPITAL</th>\n",
       "      <th>DOA</th>\n",
       "      <th>DEATH_DA</th>\n",
       "      <th>DEATH_MO</th>\n",
       "      <th>DEATH_YR</th>\n",
       "      <th>DEATH_HR</th>\n",
       "      <th>DEATH_MN</th>\n",
       "      <th>DEATH_TM</th>\n",
       "      <th>LAG_HRS</th>\n",
       "      <th>LAG_MINS</th>\n",
       "      <th>P_SF1</th>\n",
       "      <th>P_SF2</th>\n",
       "      <th>P_SF3</th>\n",
       "      <th>WORK_INJ</th>\n",
       "      <th>HISPANIC</th>\n",
       "      <th>RACE</th>\n",
       "      <th>LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82881.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58037.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>996</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58037.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>996</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10003</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63402.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>2250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10003</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7881.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>8888</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>8888</td>\n",
       "      <td>999</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATE  ST_CASE  VE_FORMS  VEH_NO  PER_NO  STR_VEH  COUNTY  DAY  MONTH  \\\n",
       "0      1    10001         1       1       1        0     121    5      1   \n",
       "1      1    10002         1       1       1        0     127    8      1   \n",
       "2      1    10002         1       1       2        0     127    8      1   \n",
       "3      1    10003         2       1       1        0      21    8      1   \n",
       "4      1    10003         2       2       1        0      21    8      1   \n",
       "\n",
       "   HOUR  MINUTE  RUR_URB  FUNC_SYS  HARM_EV  MAN_COLL  SCH_BUS  MAKE  MAK_MOD  \\\n",
       "0     6       0        1         1       14         0        0  82.0  82881.0   \n",
       "1     0      48        2         1       38         0        0  58.0  58037.0   \n",
       "2     0      48        2         1       38         0        0  58.0  58037.0   \n",
       "3    22      50        1         1       24         0        0  63.0  63402.0   \n",
       "4    22      50        1         1       24         0        0   7.0   7881.0   \n",
       "\n",
       "   BODY_TYP  MOD_YEAR  TOW_VEH  SPEC_USE  EMER_USE  ROLLOVER  IMPACT1  \\\n",
       "0      66.0    2018.0      1.0       0.0       0.0       1.0     12.0   \n",
       "1       4.0    9999.0      0.0       0.0       0.0       0.0     12.0   \n",
       "2       4.0    9999.0      0.0       0.0       0.0       0.0     12.0   \n",
       "3      14.0    2008.0      0.0       0.0       0.0       0.0     11.0   \n",
       "4      61.0    2001.0      0.0       0.0       0.0       0.0      1.0   \n",
       "\n",
       "   FIRE_EXP  AGE  SEX  PER_TYP  INJ_SEV  SEAT_POS  REST_USE  REST_MIS  \\\n",
       "0       0.0   55    1        1        4        11        20         0   \n",
       "1       1.0   24    1        1        4        11        20         0   \n",
       "2       1.0   24    1        2        4        13         3         0   \n",
       "3       0.0   37    2        1        4        11        20         0   \n",
       "4       0.0   36    1        1        2        11        20         0   \n",
       "\n",
       "   AIR_BAG  EJECTION  EJ_PATH  EXTRICAT  DRINKING  ALC_DET  ALC_STATUS  \\\n",
       "0       20         2        9         0         0        9           2   \n",
       "1        1         1        9         0         9        9           0   \n",
       "2        1         0        0         9         8        9           0   \n",
       "3        1         0        0         9         0        9           2   \n",
       "4       20         0        0         0         0        9           0   \n",
       "\n",
       "   ATST_TYP  ALC_RES  DRUGS  DRUG_DET  DSTATUS  HOSPITAL  DOA  DEATH_DA  \\\n",
       "0         1        0      0         8        2         0    7         5   \n",
       "1         0      996      9         8        0         0    7         8   \n",
       "2         0      996      8         8        0         0    7         8   \n",
       "3         1        0      9         8        2         0    7         8   \n",
       "4         0      996      0         8        0         5    0        88   \n",
       "\n",
       "   DEATH_MO  DEATH_YR  DEATH_HR  DEATH_MN  DEATH_TM  LAG_HRS  LAG_MINS  P_SF1  \\\n",
       "0         1      2018         6         0       600        0         0      0   \n",
       "1         1      2018         0        48        48        0         0      0   \n",
       "2         1      2018         0        48        48        0         0      0   \n",
       "3         1      2018        22        50      2250        0         0      0   \n",
       "4        88      8888        88        88      8888      999        99      0   \n",
       "\n",
       "   P_SF2  P_SF3  WORK_INJ  HISPANIC  RACE  LOCATION  \n",
       "0      0      0         1         7     2         0  \n",
       "1      0      0         0         7     2         0  \n",
       "2      0      0         0         7     2         0  \n",
       "3      0      0         0         7     1         0  \n",
       "4      0      0         8         0     0         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#person\n",
    "pd.read_csv(\"data/person/2018/person2018.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>ST_CASE</th>\n",
       "      <th>VEH_NO</th>\n",
       "      <th>VE_FORMS</th>\n",
       "      <th>NUMOCCS</th>\n",
       "      <th>DAY</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MINUTE</th>\n",
       "      <th>HARM_EV</th>\n",
       "      <th>MAN_COLL</th>\n",
       "      <th>UNITTYPE</th>\n",
       "      <th>HIT_RUN</th>\n",
       "      <th>REG_STAT</th>\n",
       "      <th>OWNER</th>\n",
       "      <th>MAKE</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>MAK_MOD</th>\n",
       "      <th>BODY_TYP</th>\n",
       "      <th>MOD_YEAR</th>\n",
       "      <th>VIN</th>\n",
       "      <th>VIN_1</th>\n",
       "      <th>VIN_2</th>\n",
       "      <th>VIN_3</th>\n",
       "      <th>VIN_4</th>\n",
       "      <th>VIN_5</th>\n",
       "      <th>VIN_6</th>\n",
       "      <th>VIN_7</th>\n",
       "      <th>VIN_8</th>\n",
       "      <th>VIN_9</th>\n",
       "      <th>VIN_10</th>\n",
       "      <th>VIN_11</th>\n",
       "      <th>VIN_12</th>\n",
       "      <th>TOW_VEH</th>\n",
       "      <th>J_KNIFE</th>\n",
       "      <th>MCARR_I1</th>\n",
       "      <th>MCARR_I2</th>\n",
       "      <th>MCARR_ID</th>\n",
       "      <th>GVWR</th>\n",
       "      <th>V_CONFIG</th>\n",
       "      <th>CARGO_BT</th>\n",
       "      <th>HAZ_INV</th>\n",
       "      <th>HAZ_PLAC</th>\n",
       "      <th>HAZ_ID</th>\n",
       "      <th>HAZ_CNO</th>\n",
       "      <th>HAZ_REL</th>\n",
       "      <th>BUS_USE</th>\n",
       "      <th>SPEC_USE</th>\n",
       "      <th>EMER_USE</th>\n",
       "      <th>TRAV_SP</th>\n",
       "      <th>UNDERIDE</th>\n",
       "      <th>ROLLOVER</th>\n",
       "      <th>ROLINLOC</th>\n",
       "      <th>IMPACT1</th>\n",
       "      <th>DEFORMED</th>\n",
       "      <th>TOWED</th>\n",
       "      <th>M_HARM</th>\n",
       "      <th>VEH_SC1</th>\n",
       "      <th>VEH_SC2</th>\n",
       "      <th>FIRE_EXP</th>\n",
       "      <th>DR_PRES</th>\n",
       "      <th>L_STATE</th>\n",
       "      <th>DR_ZIP</th>\n",
       "      <th>L_STATUS</th>\n",
       "      <th>L_TYPE</th>\n",
       "      <th>CDL_STAT</th>\n",
       "      <th>L_ENDORS</th>\n",
       "      <th>L_COMPL</th>\n",
       "      <th>L_RESTRI</th>\n",
       "      <th>DR_HGT</th>\n",
       "      <th>DR_WGT</th>\n",
       "      <th>PREV_ACC</th>\n",
       "      <th>PREV_SUS1</th>\n",
       "      <th>PREV_SUS2</th>\n",
       "      <th>PREV_SUS3</th>\n",
       "      <th>PREV_DWI</th>\n",
       "      <th>PREV_SPD</th>\n",
       "      <th>PREV_OTH</th>\n",
       "      <th>FIRST_MO</th>\n",
       "      <th>FIRST_YR</th>\n",
       "      <th>LAST_MO</th>\n",
       "      <th>LAST_YR</th>\n",
       "      <th>SPEEDREL</th>\n",
       "      <th>DR_SF1</th>\n",
       "      <th>DR_SF2</th>\n",
       "      <th>DR_SF3</th>\n",
       "      <th>DR_SF4</th>\n",
       "      <th>VTRAFWAY</th>\n",
       "      <th>VNUM_LAN</th>\n",
       "      <th>VSPD_LIM</th>\n",
       "      <th>VALIGN</th>\n",
       "      <th>VPROFILE</th>\n",
       "      <th>VPAVETYP</th>\n",
       "      <th>VSURCOND</th>\n",
       "      <th>VTRAFCON</th>\n",
       "      <th>VTCONT_F</th>\n",
       "      <th>P_CRASH1</th>\n",
       "      <th>P_CRASH2</th>\n",
       "      <th>P_CRASH3</th>\n",
       "      <th>PCRASH4</th>\n",
       "      <th>PCRASH5</th>\n",
       "      <th>ACC_TYPE</th>\n",
       "      <th>TRLR1VIN</th>\n",
       "      <th>TRLR2VIN</th>\n",
       "      <th>TRLR3VIN</th>\n",
       "      <th>DEATHS</th>\n",
       "      <th>DR_DRINK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>881</td>\n",
       "      <td>82881</td>\n",
       "      <td>66</td>\n",
       "      <td>2018</td>\n",
       "      <td>1FUBGDFG0JLJ</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>U</td>\n",
       "      <td>B</td>\n",
       "      <td>G</td>\n",
       "      <td>D</td>\n",
       "      <td>F</td>\n",
       "      <td>G</td>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "      <td>L</td>\n",
       "      <td>J</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>978310</td>\n",
       "      <td>57978310</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35211</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>888888888888</td>\n",
       "      <td>777777777777</td>\n",
       "      <td>777777777777</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>37</td>\n",
       "      <td>58037</td>\n",
       "      <td>4</td>\n",
       "      <td>9999</td>\n",
       "      <td>999999999999</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>000000000</td>\n",
       "      <td>00000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>38115</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>777777777777</td>\n",
       "      <td>777777777777</td>\n",
       "      <td>777777777777</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10003</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>402</td>\n",
       "      <td>63402</td>\n",
       "      <td>14</td>\n",
       "      <td>2008</td>\n",
       "      <td>KNDJD7359857</td>\n",
       "      <td>K</td>\n",
       "      <td>N</td>\n",
       "      <td>D</td>\n",
       "      <td>J</td>\n",
       "      <td>D</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>000000000</td>\n",
       "      <td>00000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35046</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>777777777777</td>\n",
       "      <td>777777777777</td>\n",
       "      <td>777777777777</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10003</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>881</td>\n",
       "      <td>7881</td>\n",
       "      <td>61</td>\n",
       "      <td>2001</td>\n",
       "      <td>3B6MC366X1M5</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>1784443</td>\n",
       "      <td>571784443</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35180</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>777777777777</td>\n",
       "      <td>777777777777</td>\n",
       "      <td>777777777777</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>482</td>\n",
       "      <td>49482</td>\n",
       "      <td>34</td>\n",
       "      <td>2004</td>\n",
       "      <td>5TBRN34164S4</td>\n",
       "      <td>5</td>\n",
       "      <td>T</td>\n",
       "      <td>B</td>\n",
       "      <td>R</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>000000000</td>\n",
       "      <td>00000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>30066</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>250</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>777777777777</td>\n",
       "      <td>777777777777</td>\n",
       "      <td>777777777777</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATE  ST_CASE  VEH_NO  VE_FORMS  NUMOCCS  DAY  MONTH  HOUR  MINUTE  \\\n",
       "0      1    10001       1         1        1    5      1     6       0   \n",
       "1      1    10002       1         1        2    8      1     0      48   \n",
       "2      1    10003       1         2        1    8      1    22      50   \n",
       "3      1    10003       2         2        1    8      1    22      50   \n",
       "4      1    10004       1         1        2    9      1    13       2   \n",
       "\n",
       "   HARM_EV  MAN_COLL  UNITTYPE  HIT_RUN  REG_STAT  OWNER  MAKE  MODEL  \\\n",
       "0       14         0         1        0         1      2    82    881   \n",
       "1       38         0         1        0        92      0    58     37   \n",
       "2       24         0         1        0         1      2    63    402   \n",
       "3       24         0         1        0         1      3     7    881   \n",
       "4       24         0         1        0        12      3    49    482   \n",
       "\n",
       "   MAK_MOD  BODY_TYP  MOD_YEAR           VIN VIN_1 VIN_2 VIN_3 VIN_4 VIN_5  \\\n",
       "0    82881        66      2018  1FUBGDFG0JLJ     1     F     U     B     G   \n",
       "1    58037         4      9999  999999999999     9     9     9     9     9   \n",
       "2    63402        14      2008  KNDJD7359857     K     N     D     J     D   \n",
       "3     7881        61      2001  3B6MC366X1M5     3     B     6     M     C   \n",
       "4    49482        34      2004  5TBRN34164S4     5     T     B     R     N   \n",
       "\n",
       "  VIN_6 VIN_7 VIN_8 VIN_9 VIN_10 VIN_11 VIN_12  TOW_VEH  J_KNIFE  MCARR_I1  \\\n",
       "0     D     F     G     0      J      L      J        1        1        57   \n",
       "1     9     9     9     9      9      9      9        0        0         0   \n",
       "2     7     3     5     9      8      5      7        0        0         0   \n",
       "3     3     6     6     X      1      M      5        0        0        57   \n",
       "4     3     4     1     6      4      S      4        0        0         0   \n",
       "\n",
       "    MCARR_I2     MCARR_ID  GVWR  V_CONFIG  CARGO_BT  HAZ_INV  HAZ_PLAC  \\\n",
       "0     978310     57978310     3         6         1        1         0   \n",
       "1  000000000  00000000000     0         0         0        1         0   \n",
       "2  000000000  00000000000     0         0         0        1         0   \n",
       "3    1784443    571784443     2         1        96        1         0   \n",
       "4  000000000  00000000000     0         0         0        1         0   \n",
       "\n",
       "   HAZ_ID  HAZ_CNO  HAZ_REL  BUS_USE  SPEC_USE  EMER_USE  TRAV_SP  UNDERIDE  \\\n",
       "0       0        0        0        0         0         0       60         0   \n",
       "1       0        0        0        0         0         0      120         0   \n",
       "2       0        0        0        0         0         0       65         0   \n",
       "3       0        0        0        0         0         0       70         0   \n",
       "4       0        0        0        0         0         0      999         0   \n",
       "\n",
       "   ROLLOVER  ROLINLOC  IMPACT1  DEFORMED  TOWED  M_HARM  VEH_SC1  VEH_SC2  \\\n",
       "0         1         1       12         6      2       1        0        0   \n",
       "1         0         0       12         6      2      32        0        0   \n",
       "2         0         0       11         6      2      12        0        0   \n",
       "3         0         0        1         6      2      12        0        0   \n",
       "4         0         0       11         6      2      24        0        0   \n",
       "\n",
       "   FIRE_EXP  DR_PRES  L_STATE  DR_ZIP  L_STATUS  L_TYPE  CDL_STAT  L_ENDORS  \\\n",
       "0         0        1        1   35211         6       1         6         0   \n",
       "1         1        1       47   38115         2       1         0         0   \n",
       "2         0        1        1   35046         2       1         0         0   \n",
       "3         0        1        1   35180         6       1         0         0   \n",
       "4         0        1       13   30066         1       1         0         0   \n",
       "\n",
       "   L_COMPL  L_RESTRI  DR_HGT  DR_WGT  PREV_ACC  PREV_SUS1  PREV_SUS2  \\\n",
       "0        3         0      69     210         0          0          0   \n",
       "1        2         0      68     140         3          0          0   \n",
       "2        2         0      68     185         1          0          2   \n",
       "3        3         0      74     200         1          0          0   \n",
       "4        2         1      74     250        98          0          0   \n",
       "\n",
       "   PREV_SUS3  PREV_DWI  PREV_SPD  PREV_OTH  FIRST_MO  FIRST_YR  LAST_MO  \\\n",
       "0          0         0         1         0         9      2016        9   \n",
       "1          5         0         0         0         2      2013        9   \n",
       "2          0         2         0         1         7      2016        9   \n",
       "3          0         0         1         3         2      2016        6   \n",
       "4          0         0         2         0        12      2013        1   \n",
       "\n",
       "   LAST_YR  SPEEDREL  DR_SF1  DR_SF2  DR_SF3  DR_SF4  VTRAFWAY  VNUM_LAN  \\\n",
       "0     2016         0       0       0       0       0         2         2   \n",
       "1     2015         3       8      37       0       0         2         2   \n",
       "2     2017         0       0       0       0       0         2         2   \n",
       "3     2016         0       0       0       0       0         2         2   \n",
       "4     2017         9      58       0       0       0         2         2   \n",
       "\n",
       "   VSPD_LIM  VALIGN  VPROFILE  VPAVETYP  VSURCOND  VTRAFCON  VTCONT_F  \\\n",
       "0        70       1         1         2         1         0         0   \n",
       "1        70       1         1         2         2         0         0   \n",
       "2        55       1         1         2         2         0         0   \n",
       "3        55       1         1         2         2         0         0   \n",
       "4        70       1         1         2         1         0         0   \n",
       "\n",
       "   P_CRASH1  P_CRASH2  P_CRASH3  PCRASH4  PCRASH5  ACC_TYPE      TRLR1VIN  \\\n",
       "0         1        11        99        1        4        11  888888888888   \n",
       "1         1        12         1        1        4         6  777777777777   \n",
       "2         1        90         6        1        4         3  777777777777   \n",
       "3         1        61        16        1        1        98  777777777777   \n",
       "4         1        12         7        3        4         2  777777777777   \n",
       "\n",
       "       TRLR2VIN      TRLR3VIN  DEATHS  DR_DRINK  \n",
       "0  777777777777  777777777777       1         0  \n",
       "1  777777777777  777777777777       2         0  \n",
       "2  777777777777  777777777777       1         0  \n",
       "3  777777777777  777777777777       0         0  \n",
       "4  777777777777  777777777777       1         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vehicle\n",
    "pd.read_csv(\"data/vehicle/2018/vehicle2018.csv\", encoding='windows-1252', low_memory=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Territory</th>\n",
       "      <th>State Name</th>\n",
       "      <th>State Code</th>\n",
       "      <th>City Code</th>\n",
       "      <th>City Name</th>\n",
       "      <th>County Code</th>\n",
       "      <th>County Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Old City Name</th>\n",
       "      <th>Date Record Added</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>67</td>\n",
       "      <td>HENRY</td>\n",
       "      <td>840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>ALBERTVILLE</td>\n",
       "      <td>95</td>\n",
       "      <td>MARSHALL</td>\n",
       "      <td>840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>ALEXANDER CITY</td>\n",
       "      <td>123</td>\n",
       "      <td>TALLAPOOSA</td>\n",
       "      <td>840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>ALICEVILLE</td>\n",
       "      <td>107</td>\n",
       "      <td>PICKENS</td>\n",
       "      <td>840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>ANDALUSIA</td>\n",
       "      <td>39</td>\n",
       "      <td>COVINGTON</td>\n",
       "      <td>840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Territory State Name  State Code  City Code       City Name  County Code  \\\n",
       "0         U    ALABAMA           1         10       ABBEVILLE           67   \n",
       "1         U    ALABAMA           1         50     ALBERTVILLE           95   \n",
       "2         U    ALABAMA           1         60  ALEXANDER CITY          123   \n",
       "3         U    ALABAMA           1         70      ALICEVILLE          107   \n",
       "4         U    ALABAMA           1         90       ANDALUSIA           39   \n",
       "\n",
       "  County Name  Country Code Old City Name Date Record Added  \n",
       "0       HENRY         840.0           NaN               NaT  \n",
       "1    MARSHALL         840.0           NaN               NaT  \n",
       "2  TALLAPOOSA         840.0           NaN               NaT  \n",
       "3     PICKENS         840.0           NaN               NaT  \n",
       "4   COVINGTON         840.0           NaN               NaT  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#glc\n",
    "pd.read_excel(\"data/glc/glc.xlsx\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspection and trial code runs, we are concerned with the following five data cleaning issues:\n",
    "\n",
    "* Duplication: If any, duplicate rows must be removed.\n",
    "* Nulls: Null/empty values must be removed from the columns of interest.\n",
    "* Reduction: Unused columns must be dropped in order to reduce our table sizes for faster queries.\n",
    "* Codification: Since all of the raw traffic data is codified, required details must be entered in according to the [FARS Analytical User's Manual](https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812827) (Exceptions will be the `make` and `model` in the `vehicle` and `cars` tables - due to long lists of values, we will refer our data users to [FARS/CRSS Coding and Validation Manual](https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812828)).\n",
    "* Column capitalization: Because Redshift is not case sensitive and all column names default to lowercase, this can pose an issue when copying the template data tables. Therefore, all columns must be lowercased.\n",
    "* City name formatting: First few trial code runs have revealed that many of the city names on the `glc` template table has characters that interfere with proper Redshift loading. To address this, those chracters will be removed from the column. \n",
    "\n",
    "We will take the following data cleaning steps:     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Steps\n",
    "\n",
    "##### Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accident\n",
    "accident2016df = pd.read_csv(\"data/accident/2016/accident2016.csv\").drop_duplicates()\n",
    "accident2017df = pd.read_csv(\"data/accident/2017/accident2017.csv\").drop_duplicates()\n",
    "accident2018df = pd.read_csv(\"data/accident/2018/accident2018.csv\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drimpair\n",
    "drimpair2016df = pd.read_csv(\"data/drimpair/2016/drimpair2016.csv\").drop_duplicates()\n",
    "drimpair2017df = pd.read_csv(\"data/drimpair/2017/drimpair2017.csv\").drop_duplicates()\n",
    "drimpair2018df = pd.read_csv(\"data/drimpair/2018/drimpair2018.csv\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nmimpair\n",
    "nmimpair2016df = pd.read_csv(\"data/nmimpair/2016/nmimpair2016.csv\").drop_duplicates()\n",
    "nmimpair2017df = pd.read_csv(\"data/nmimpair/2017/nmimpair2017.csv\").drop_duplicates()\n",
    "nmimpair2018df = pd.read_csv(\"data/nmimpair/2018/nmimpair2018.csv\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#person\n",
    "person2016df = pd.read_csv(\"data/person/2016/person2016.csv\").drop_duplicates()\n",
    "person2017df = pd.read_csv(\"data/person/2017/person2017.csv\").drop_duplicates()\n",
    "person2018df = pd.read_csv(\"data/person/2018/person2018.csv\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vehicle\n",
    "vehicle2016df = pd.read_csv(\"data/vehicle/2016/vehicle2016.csv\", encoding='windows-1252', low_memory=False).drop_duplicates()\n",
    "vehicle2017df = pd.read_csv(\"data/vehicle/2017/vehicle2017.csv\", encoding='windows-1252', low_memory=False).drop_duplicates()\n",
    "vehicle2018df = pd.read_csv(\"data/vehicle/2018/vehicle2018.csv\", encoding='windows-1252', low_memory=False).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glc\n",
    "glcdf = pd.read_excel(\"data/glc/glc.xlsx\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove Nulls and Reduce Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_reduce(df, col_list):\n",
    "    for i in col_list:\n",
    "        df = df[pd.notnull(df[i])]\n",
    "    df = df[col_list] \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accident\n",
    "col_list = ['STATE', 'ST_CASE', 'COUNTY', 'CITY', 'DAY', 'MONTH', 'YEAR', 'DAY_WEEK', 'HOUR', 'MINUTE', \n",
    "            'LATITUDE', 'LONGITUD', 'FATALS'] \n",
    "\n",
    "accident2016df = remove_reduce(accident2016df, col_list)\n",
    "accident2017df = remove_reduce(accident2017df, col_list)\n",
    "accident2018df = remove_reduce(accident2018df, col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drimpair\n",
    "col_list = ['STATE', 'ST_CASE', 'VEH_NO', 'DRIMPAIR'] \n",
    "\n",
    "drimpair2016df = remove_reduce(drimpair2016df, col_list)\n",
    "drimpair2017df = remove_reduce(drimpair2017df, col_list)\n",
    "drimpair2018df = remove_reduce(drimpair2018df, col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nmimpair\n",
    "col_list = ['STATE', 'ST_CASE', 'VEH_NO', 'PER_NO', 'NMIMPAIR'] \n",
    "\n",
    "nmimpair2016df = remove_reduce(nmimpair2016df, col_list)\n",
    "nmimpair2017df = remove_reduce(nmimpair2017df, col_list)\n",
    "nmimpair2018df = remove_reduce(nmimpair2018df, col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#person\n",
    "col_list = ['STATE', 'ST_CASE', 'VEH_NO', 'PER_NO', 'COUNTY', 'DAY', 'MONTH', 'HOUR', 'MINUTE', 'AGE', 'SEX', \n",
    "            'PER_TYP', 'INJ_SEV']\n",
    "\n",
    "person2016df = remove_reduce(person2016df, col_list)\n",
    "person2017df = remove_reduce(person2017df, col_list)\n",
    "person2018df = remove_reduce(person2018df, col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vehicle\n",
    "col_list = ['STATE', 'ST_CASE', 'VEH_NO', 'DAY', 'MONTH', 'HOUR', 'MINUTE', 'MAKE', 'MODEL', 'MOD_YEAR', \n",
    "            'DEFORMED']\n",
    "\n",
    "vehicle2016df = remove_reduce(vehicle2016df, col_list)\n",
    "vehicle2017df = remove_reduce(vehicle2017df, col_list)\n",
    "vehicle2018df = remove_reduce(vehicle2018df, col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glc\n",
    "col_list = ['State Name', 'State Code', 'City Code', 'City Name', 'County Code', 'County Name']\n",
    "\n",
    "glcdf = remove_reduce(glcdf, col_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_codes(df, dic):\n",
    "    df = df.replace(to_replace=dic, value=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drimpair\n",
    "dic = {'DRIMPAIR': {0: 'None/Apparently Normal', \n",
    "                    1: \"Ill/ Blackout\", \n",
    "                    2: \"Asleep or Fatigued\",\n",
    "                    3: 'Walking with a Cane or Crutches.', \n",
    "                    4: 'Paraplegic or in a Wheelchair', \n",
    "                    5: 'Impaired Due to Previous Injury', \n",
    "                    6: 'Deaf', \n",
    "                    7: 'Blind', \n",
    "                    8: 'Emotional (Depressed/ Angry/ Disturbed.)', \n",
    "                    9: 'Under the Influence of Alcohol/ Drugs or Medication', \n",
    "                    10: 'Physical Impairment â€“ No Details', \n",
    "                    95: 'No Driver Present/Unknown if Driver Present', \n",
    "                    96: 'Other Physical Impairment', \n",
    "                    98: 'Not Reported', \n",
    "                    99: 'Reported as Unknown if Impaired'}}\n",
    "\n",
    "drimpair2016df = replace_codes(drimpair2016df, dic)\n",
    "drimpair2017df = replace_codes(drimpair2017df, dic)\n",
    "drimpair2018df = replace_codes(drimpair2018df, dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nmimpair\n",
    "dic = {'NMIMPAIR': {0: 'None/Apparently Normal', \n",
    "                    1: 'Ill/ Blackout', \n",
    "                    2: 'Asleep or Fatigued',\n",
    "                    3: 'Walking with a Cane or Crutches.', \n",
    "                    4: 'Paraplegic or in a Wheelchair', \n",
    "                    5: 'Impaired Due to Previous Injury', \n",
    "                    6: 'Deaf', \n",
    "                    7: 'Blind', \n",
    "                    8: 'Emotional (Depressed/ Angry/ Disturbed.)', \n",
    "                    9: 'Under the Influence of Alcohol; Drugs or Medication', \n",
    "                    10: 'Physical Impairment â€“ No Details', \n",
    "                    95: 'No Driver Present/Unknown if Driver Present', \n",
    "                    96: 'Other Physical Impairment', \n",
    "                    98: 'Not Reported', \n",
    "                    99: 'Unknown'}}\n",
    "\n",
    "nmimpair2016df = replace_codes(nmimpair2016df, dic)\n",
    "nmimpair2017df = replace_codes(nmimpair2017df, dic)\n",
    "nmimpair2018df = replace_codes(nmimpair2018df, dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#person\n",
    "dic = {'SEX': {1: 'Male',\n",
    "               2: 'Female',\n",
    "               8: 'Not Reported',\n",
    "               9: 'Unknown'},\n",
    "       'PER_TYP': {1: 'Driver of a Motor Vehicle In-Transport', \n",
    "                   2: 'Passenger of a Motor Vehicle In-Transport', \n",
    "                   3: 'Occupant of a Motor Vehicle Not In-Transport', \n",
    "                   4: 'Occupant of a Non-Motor Vehicle Transport Device', \n",
    "                   5: 'Pedestrian', \n",
    "                   6: 'Bicyclist', \n",
    "                   7: 'Other Cyclist', \n",
    "                   8: 'Person on Personal Conveyances', \n",
    "                   9: 'Unknown Occupant Type in a Motor Vehicle In-Transport', \n",
    "                   10: 'Persons In/On Buildings', \n",
    "                   19: 'Unknown Type of Non-Motorist'}, \n",
    "       'INJ_SEV': {0: 'No Apparent Injury', \n",
    "                   1: 'Possible Injury', \n",
    "                   2: 'Suspected Minor Injury', \n",
    "                   3: 'Suspected Serious Injury', \n",
    "                   4: 'Fatal Injury', \n",
    "                   5: 'Injured; Severity Unknown', \n",
    "                   6: 'Died Prior to Crash', \n",
    "                   9: 'Unknown/Not Reported'}}\n",
    "\n",
    "person2016df = replace_codes(person2016df, dic)\n",
    "person2017df = replace_codes(person2017df, dic)\n",
    "person2018df = replace_codes(person2018df, dic)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vehicle\n",
    "dic = {'DEFORMED': {0: 'No Damage', \n",
    "                    2: 'Minor Damage', \n",
    "                    4: 'Functional Damage',\n",
    "                    6: 'Disabling Damage',\n",
    "                    8: 'Not Reported',\n",
    "                    9: 'Unknown'}} \n",
    "\n",
    "vehicle2016df = replace_codes(vehicle2016df, dic)\n",
    "vehicle2017df = replace_codes(vehicle2017df, dic)\n",
    "vehicle2018df = replace_codes(vehicle2018df, dic) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lowercase Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(df, dic):\n",
    "    df = df.rename(columns=dic)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accident\n",
    "dic = {'STATE': 'state', 'ST_CASE': 'st_case', 'COUNTY': 'county', 'CITY': 'city', 'DAY': 'day', 'MONTH': 'month', \n",
    "       'YEAR': 'year', 'DAY_WEEK': 'day_week', 'HOUR': 'hour', 'MINUTE': 'minute', 'LATITUDE': 'latitude', \n",
    "       'LONGITUD': 'longitud', 'FATALS': 'fatals'} \n",
    "\n",
    "accident2016df = lowercase(accident2016df, dic)\n",
    "accident2017df = lowercase(accident2017df, dic)\n",
    "accident2018df = lowercase(accident2018df, dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drimpair\n",
    "dic = {'STATE': 'state', 'ST_CASE': 'st_case', 'VEH_NO': 'veh_no', 'DRIMPAIR': 'drimpair'} \n",
    "\n",
    "drimpair2016df = lowercase(drimpair2016df, dic)\n",
    "drimpair2017df = lowercase(drimpair2017df, dic)\n",
    "drimpair2018df = lowercase(drimpair2018df, dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nmimpair\n",
    "dic = {'STATE': 'state', 'ST_CASE': 'st_case', 'VEH_NO': 'veh_no', 'PER_NO': 'per_no', 'NMIMPAIR': 'nmimpair'}\n",
    "\n",
    "nmimpair2016df = lowercase(nmimpair2016df, dic)\n",
    "nmimpair2017df = lowercase(nmimpair2017df, dic)\n",
    "nmimpair2018df = lowercase(nmimpair2018df, dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#person\n",
    "dic = {'STATE': 'state', 'ST_CASE': 'st_case', 'VEH_NO': 'veh_no', 'PER_NO': 'per_no', 'COUNTY': 'county', \n",
    "       'DAY': 'day', 'MONTH': 'month', 'HOUR': 'hour', 'MINUTE': 'minute', 'AGE': 'age', 'SEX': 'sex', \n",
    "       'PER_TYP': 'per_typ', 'INJ_SEV': 'inj_sev'}\n",
    "\n",
    "person2016df = lowercase(person2016df, dic)\n",
    "person2017df = lowercase(person2017df, dic)\n",
    "person2018df = lowercase(person2018df, dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vehicle\n",
    "dic = {'STATE': 'state', 'ST_CASE': 'st_case', 'VEH_NO': 'veh_no', 'DAY': 'day', 'MONTH': 'month', 'HOUR': 'hour', \n",
    "       'MINUTE': 'minute', 'MAKE': 'make', 'MODEL': 'model', 'MOD_YEAR': 'mod_year', 'DEFORMED': 'deformed'}\n",
    "\n",
    "vehicle2016df = lowercase(vehicle2016df, dic)\n",
    "vehicle2017df = lowercase(vehicle2017df, dic)\n",
    "vehicle2018df = lowercase(vehicle2018df, dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glc\n",
    "dic = {'State Name': 'state_name', 'State Code': 'state_code', 'City Code': 'city_code', 'City Name': 'city_name', \n",
    "       'County Code': 'county_code', 'County Name': 'county_name'}\n",
    "\n",
    "glcdf = lowercase(glcdf, dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Format City Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cities(x):\n",
    "    for i in ['\\n', '\"', '\"', ',']:\n",
    "        x = x.replace(i, ' ')\n",
    "    return x\n",
    "\n",
    "glcdf['city_name'] = glcdf['city_name'].apply(clean_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now save the dataframes into csv files locally and then to S3, under \"cleaned_data\" directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')\n",
    "\n",
    "s3_client = boto3.client('s3', aws_access_key_id=config.get('AWS','aws_access_key_id'), aws_secret_access_key=config.get('AWS','aws_secret_access_key'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accident\n",
    "accident2016df.to_csv (\"cleaned_data/accident/2016/accident2016c.csv\", index = None, header=True)\n",
    "accident2017df.to_csv (\"cleaned_data/accident/2017/accident2017c.csv\", index = None, header=True)\n",
    "accident2018df.to_csv (\"cleaned_data/accident/2018/accident2018c.csv\", index = None, header=True)\n",
    "\n",
    "for i in ['cleaned_data/accident/2016/accident2016c.csv', 'cleaned_data/accident/2017/accident2017c.csv', 'cleaned_data/accident/2018/accident2018c.csv']:\n",
    "    s3_client.upload_file(f'{i}', config.get('S3','bucket'), f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drimpair\n",
    "drimpair2016df.to_csv (\"cleaned_data/drimpair/2016/drimpair2016c.csv\", index = None, header=True)\n",
    "drimpair2017df.to_csv (\"cleaned_data/drimpair/2017/drimpair2017c.csv\", index = None, header=True)\n",
    "drimpair2018df.to_csv (\"cleaned_data/drimpair/2018/drimpair2018c.csv\", index = None, header=True)\n",
    "\n",
    "for i in ['cleaned_data/drimpair/2016/drimpair2016c.csv', 'cleaned_data/drimpair/2017/drimpair2017c.csv', 'cleaned_data/drimpair/2018/drimpair2018c.csv']:\n",
    "    s3_client.upload_file(f'{i}', config.get('S3','bucket'), f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nmimpair\n",
    "nmimpair2016df.to_csv (\"cleaned_data/nmimpair/2016/nmimpair2016c.csv\", index = None, header=True)\n",
    "nmimpair2017df.to_csv (\"cleaned_data/nmimpair/2017/nmimpair2017c.csv\", index = None, header=True)\n",
    "nmimpair2018df.to_csv (\"cleaned_data/nmimpair/2018/nmimpair2018c.csv\", index = None, header=True)\n",
    "\n",
    "for i in ['cleaned_data/nmimpair/2016/nmimpair2016c.csv', 'cleaned_data/nmimpair/2017/nmimpair2017c.csv', 'cleaned_data/nmimpair/2018/nmimpair2018c.csv']:\n",
    "    s3_client.upload_file(f'{i}', config.get('S3','bucket'), f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#person\n",
    "person2016df.to_csv (\"cleaned_data/person/2016/person2016c.csv\", index = None, header=True)\n",
    "person2017df.to_csv (\"cleaned_data/person/2017/person2017c.csv\", index = None, header=True)\n",
    "person2018df.to_csv (\"cleaned_data/person/2018/person2018c.csv\", index = None, header=True)\n",
    "\n",
    "for i in ['cleaned_data/person/2016/person2016c.csv', 'cleaned_data/person/2017/person2017c.csv', 'cleaned_data/person/2018/person2018c.csv']:\n",
    "    s3_client.upload_file(f'{i}', config.get('S3','bucket'), f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vehicle\n",
    "vehicle2016df.to_csv (\"cleaned_data/vehicle/2016/vehicle2016c.csv\", index = None, header=True)\n",
    "vehicle2017df.to_csv (\"cleaned_data/vehicle/2017/vehicle2017c.csv\", index = None, header=True)\n",
    "vehicle2018df.to_csv (\"cleaned_data/vehicle/2018/vehicle2018c.csv\", index = None, header=True)\n",
    "\n",
    "for i in ['cleaned_data/vehicle/2016/vehicle2016c.csv', 'cleaned_data/vehicle/2017/vehicle2017c.csv', 'cleaned_data/vehicle/2018/vehicle2018c.csv']:\n",
    "    s3_client.upload_file(f'{i}', config.get('S3','bucket'), f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glc\n",
    "glcdf.to_csv (\"cleaned_data/glc/glcc.csv\", index = None, header=True)\n",
    "\n",
    "for i in ['cleaned_data/glc/glcc.csv']:\n",
    "    s3_client.upload_file(f'{i}', config.get('S3','bucket'), f'{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "For the most optimal organization, joins, and queries, we will perform dimensional data modeling to create the following star schema:\n",
    "\n",
    "**Fact Table**\n",
    "\n",
    "1. **crashes**\n",
    "\n",
    "    - case_id, date_id, loc_id, car_id1, car_id2, car_id3, car_id4, nm_id1, nm_id2, nm_id3, nm_id4, fatalities\n",
    "\n",
    "**Dimension Tables**\n",
    "\n",
    "2. **dates**\n",
    "    - date_id, case_id, year, month, day, weekday, hour, minute\n",
    "\n",
    "3. **location**\n",
    "    - loc_id, case_id, state, city, county, latitude, longitude\n",
    "    \n",
    "4. **cars**\n",
    "    - car_id, case_id, make, model, mod_year, damage, dr_age, dr_sex, dr_injury, dr_impair\n",
    "    \n",
    "5. **non_motorists**\n",
    "    - nm_id, case_id, nm_type, nm_age, nm_sex, nm_injury, nm_impair\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "We will take the following steps to create our data model:\n",
    "\n",
    "1. Create empty tables in the Redshift cluster.\n",
    "2. Load the csv file data into template redshift tables (`accident`, `drimpair`, `nmimpair`, `person`, `vehicle`, `glc`).\n",
    "3. Query and join the template tables to reorganize and load the data into the fact and dimension tables.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connect API to Redshift \n",
    "We begin by connecting our Jupyter Notebook to Redshift cluster and launching session. To test, user must launch a Redshift cluster on AWS with API and S3 access enabled, and enter the required credentials in the dwh.cfg file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(f\"host={config.get('REDSHIFT','host')} dbname={config.get('REDSHIFT','dbname')} user={config.get('REDSHIFT','user')} password={config.get('REDSHIFT','password')} port={config.get('REDSHIFT','port')}\")\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Tables\n",
    "Now we create the tables on Redshift. Table dropping query is executed first each time to allow data reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accident\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    accident_drop = f\"DROP table IF EXISTS accident{i}\"\n",
    "    accident_create = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS accident{i} \n",
    "    (state int, st_case int, county int, city int, day int, month int, year int, day_week int, hour int, minute int, \n",
    "    latitude decimal, longitud decimal, fatals int)\n",
    "    \"\"\"\n",
    "    cur.execute(accident_drop)\n",
    "    cur.execute(accident_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drimpair\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    drimpair_drop = f\"DROP table IF EXISTS drimpair{i}\"\n",
    "    drimpair_create = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS drimpair{i} \n",
    "    (state int, st_case int, veh_no int, drimpair text)\n",
    "    \"\"\"\n",
    "    cur.execute(drimpair_drop)\n",
    "    cur.execute(drimpair_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nmimpair\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    nmimpair_drop = f\"DROP table IF EXISTS nmimpair{i}\"\n",
    "    nmimpair_create = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS nmimpair{i} \n",
    "    (state int, st_case int, veh_no int, per_no int, nmimpair text)\n",
    "    \"\"\"\n",
    "    cur.execute(nmimpair_drop)\n",
    "    cur.execute(nmimpair_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#person\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    person_drop = f\"DROP table IF EXISTS person{i}\"\n",
    "    person_create = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS person{i}\n",
    "    (state int, st_case int, veh_no int, per_no int, county int, day int, month int, hour int, minute int, age int, \n",
    "    sex text, per_typ text, inj_sev text)\n",
    "    \"\"\"\n",
    "    cur.execute(person_drop)\n",
    "    cur.execute(person_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vehicle\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    vehicle_drop = f\"DROP table IF EXISTS vehicle{i}\"\n",
    "    vehicle_create = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS vehicle{i}\n",
    "    (state int, st_case int, veh_no int, day int, month int, hour int, minute int, make int, model int, mod_year int, \n",
    "    deformed text)\n",
    "    \"\"\"\n",
    "    cur.execute(vehicle_drop)\n",
    "    cur.execute(vehicle_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glc\n",
    "glc_drop = f\"DROP table IF EXISTS glc\"\n",
    "glc_create = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS glc \n",
    "(state_name text, state_code int, city_code int, city_name text, county_code int, county_name text)\n",
    "\"\"\"\n",
    "cur.execute(glc_drop)\n",
    "cur.execute(glc_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crashes\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    crashes_drop = f\"DROP table IF EXISTS crashes{i}\"\n",
    "    crashes_create = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS crashes{i}\n",
    "    (case_id int, date_id int, loc_id int, car_id1 numeric, car_id2 numeric, car_id3 numeric, car_id4 numeric, \n",
    "    nm_id1 numeric, nm_id2 numeric, nm_id3 numeric, nm_id4 numeric, fatalities int)\n",
    "    \"\"\"\n",
    "    cur.execute(crashes_drop)\n",
    "    cur.execute(crashes_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    dates_drop = f\"DROP table IF EXISTS dates{i}\"\n",
    "    dates_create = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS dates{i}\n",
    "    (date_id int identity(0,1), case_id int, year int, month int, day int, weekday int, hour int, minute int)\n",
    "    \"\"\"\n",
    "    cur.execute(dates_drop)\n",
    "    cur.execute(dates_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    location_drop = f\"DROP table IF EXISTS location{i}\"\n",
    "    location_create = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS location{i}\n",
    "    (loc_id int identity(0,1), case_id int, state text, city text, county text, latitude numeric, longitude numeric)\n",
    "    \"\"\"\n",
    "    cur.execute(location_drop)\n",
    "    cur.execute(location_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cars\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    cars_drop = f\"DROP table IF EXISTS cars{i}\"\n",
    "    cars_create = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS cars{i}\n",
    "    (car_id int identity(0,1), case_id int, make int, model int, mod_year int, damage text, dr_age int, \n",
    "    dr_sex text, dr_injury text, dr_impair text)\n",
    "    \"\"\"\n",
    "    cur.execute(cars_drop)\n",
    "    cur.execute(cars_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non_motorists\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    non_motorists_drop = f\"DROP table IF EXISTS non_motorists{i}\"\n",
    "    non_motorists_create = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS non_motorists{i}\n",
    "    (nm_id int identity(0,1), case_id int, nm_type text, nm_age int, nm_sex text, nm_injury text, \n",
    "    nm_impair text)\n",
    "    \"\"\"\n",
    "    cur.execute(non_motorists_drop)\n",
    "    cur.execute(non_motorists_create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Template Tables\n",
    "Now we load the template tables (`accident`, `drimpair`, `nmimpair`, `person`, `vehicle`, `glc`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['accident2016', 'drimpair2016', 'nmimpair2016', 'person2016', 'vehicle2016',\n",
    "          'accident2017', 'drimpair2017', 'nmimpair2017', 'person2017', 'vehicle2017',\n",
    "          'accident2018', 'drimpair2018', 'nmimpair2018', 'person2018', 'vehicle2018']:\n",
    "    load_traffic_query = f\"\"\"\n",
    "    COPY {i}\n",
    "    FROM 's3://{config.get('S3','bucket')}/cleaned_data/{i[:-4]}/{i[-4:]}'\n",
    "    ACCESS_KEY_ID '{config.get('AWS','aws_access_key_id')}'\n",
    "    SECRET_ACCESS_KEY '{config.get('AWS','aws_secret_access_key')}'\n",
    "    IGNOREHEADER 1\n",
    "    DELIMITER ','\n",
    "    \"\"\"\n",
    "    cur.execute(load_traffic_query)\n",
    "\n",
    "load_glc_query = f\"\"\"\n",
    "COPY glc\n",
    "FROM 's3://{config.get('S3','bucket')}/cleaned_data/glc'\n",
    "ACCESS_KEY_ID '{config.get('AWS','aws_access_key_id')}'\n",
    "SECRET_ACCESS_KEY '{config.get('AWS','aws_secret_access_key')}'\n",
    "IGNOREHEADER 1\n",
    "DELIMITER ','\n",
    "\"\"\"\n",
    "cur.execute(load_glc_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform Data and Load Fact and Dimension Tables\n",
    "\n",
    "From our template tables, we will transform the data via query and load it into our fact and dimension tables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    dates_insert = f\"\"\"\n",
    "    INSERT INTO dates{i} (case_id, year, month, day, weekday, hour, minute)\n",
    "    SELECT st_case,\n",
    "           year,\n",
    "           month,\n",
    "           day,\n",
    "           day_week,\n",
    "           hour,\n",
    "           minute\n",
    "    FROM accident{i};\n",
    "    \"\"\"\n",
    "    cur.execute(dates_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    location_insert = f\"\"\"\n",
    "    INSERT INTO location{i} (case_id, state, city, county, latitude, longitude)\n",
    "    SELECT a.st_case,\n",
    "           g.state_name,\n",
    "           g.city_name,\n",
    "           g.county_name, \n",
    "           a.latitude,\n",
    "           a.longitud\n",
    "    FROM accident{i} a\n",
    "    JOIN glc g\n",
    "    ON a.state = g.state_code AND  \n",
    "       a.county = g.county_code AND \n",
    "       a.city = g.city_code\n",
    "    \"\"\"\n",
    "    cur.execute(location_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cars (Note: Drivers correspond to per_no = 1 in the person template table)\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    cars_insert = f\"\"\"\n",
    "    INSERT INTO cars{i} (case_id, make, model, mod_year, damage, dr_age, dr_sex, dr_injury, dr_impair)\n",
    "    SELECT v.st_case,\n",
    "           v.make,\n",
    "           v.model,\n",
    "           v.mod_year, \n",
    "           v.deformed,\n",
    "           p.age,\n",
    "           p.sex,\n",
    "           p.inj_sev,\n",
    "           d.drimpair\n",
    "    FROM vehicle{i} v\n",
    "    JOIN (SELECT *\n",
    "          FROM person{i}\n",
    "          WHERE per_no = 1) p\n",
    "    ON v.state = p.state AND  \n",
    "       v.st_case = p.st_case AND \n",
    "       v.veh_no = p.veh_no\n",
    "    JOIN drimpair{i} d\n",
    "    ON v.state = d.state AND  \n",
    "       v.st_case = d.st_case AND \n",
    "       v.veh_no = d.veh_no\n",
    "    \"\"\"\n",
    "    cur.execute(cars_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non_motorists (Note: Non_motorists correspond to veh_no = 0 in the person template table)\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    non_motorists_insert = f\"\"\"\n",
    "    INSERT INTO non_motorists{i} (case_id, nm_type, nm_age, nm_sex, nm_injury, nm_impair)\n",
    "    SELECT p.st_case,\n",
    "           p.per_typ,\n",
    "           p.age,\n",
    "           p.sex, \n",
    "           p.inj_sev,\n",
    "           n.nmimpair\n",
    "    FROM (SELECT *\n",
    "          FROM person{i}\n",
    "          WHERE veh_no = 0) p\n",
    "    JOIN nmimpair{i} n\n",
    "    ON p.state = n.state AND  \n",
    "       p.st_case = n.st_case AND \n",
    "       p.veh_no = n.veh_no\n",
    "    \"\"\"\n",
    "    cur.execute(non_motorists_insert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `crashes` fact table, all the dimension tables must be joined to the `accident` table, but the tables `cars` and `non_motorists` must be pivoted first to move `car_id` and `nm_id` rows to columns. Unfortunately, Redshift does not have any table function for pivot, but [Postgres does](https://www.postgresql.org/docs/9.2/tablefunc.html). Therefore, for this final table, we will utilize Postgres - we will create a Postgres database on AWS, load required segments of the dimension tables, alter and join them, and load the product back into Redshift to finish creating the `crashes` fact table. \n",
    "\n",
    "We first begin by extracting required segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates_segment\n",
    "dsq = \"\"\" \n",
    "SELECT case_id,\n",
    "       date_id\n",
    "FROM dates{}\n",
    "\"\"\"\n",
    "dates_segment2016df = pd.read_sql_query(dsq.format('2016'), conn)\n",
    "dates_segment2017df = pd.read_sql_query(dsq.format('2017'), conn)\n",
    "dates_segment2018df = pd.read_sql_query(dsq.format('2018'), conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location_segment\n",
    "lsq = \"\"\" \n",
    "SELECT case_id,\n",
    "       loc_id\n",
    "FROM location{}\n",
    "\"\"\"\n",
    "location_segment2016df = pd.read_sql_query(lsq.format('2016'), conn)\n",
    "location_segment2017df = pd.read_sql_query(lsq.format('2017'), conn)\n",
    "location_segment2018df = pd.read_sql_query(lsq.format('2018'), conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cars_segment\n",
    "csq = \"\"\" \n",
    "SELECT case_id,\n",
    "       make,\n",
    "       car_id\n",
    "FROM cars{}\n",
    "\"\"\"\n",
    "cars_segment2016df = pd.read_sql_query(csq.format('2016'), conn)\n",
    "cars_segment2017df = pd.read_sql_query(csq.format('2017'), conn)\n",
    "cars_segment2018df = pd.read_sql_query(csq.format('2018'), conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non_motorists_segment\n",
    "nmsq = \"\"\" \n",
    "SELECT case_id,\n",
    "       nm_type,\n",
    "       nm_id\n",
    "FROM non_motorists{}\n",
    "\"\"\" \n",
    "non_motorists_segment2016df = pd.read_sql_query(nmsq.format('2016'), conn) \n",
    "non_motorists_segment2017df = pd.read_sql_query(nmsq.format('2017'), conn) \n",
    "non_motorists_segment2018df = pd.read_sql_query(nmsq.format('2018'), conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accident_segment\n",
    "asq = \"\"\" \n",
    "SELECT st_case,\n",
    "       fatals\n",
    "FROM accident{}\n",
    "\"\"\" \n",
    "accident_segment2016df = pd.read_sql_query(asq.format('2016'), conn) \n",
    "accident_segment2017df = pd.read_sql_query(asq.format('2017'), conn) \n",
    "accident_segment2018df = pd.read_sql_query(asq.format('2018'), conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will close the Redshift connection and connect to a Postgres database (To test, user must create his own Postgres instance and enter the credentials in the dwh.cfg file). We will then load the extracted segment dataframes into the the Postgres database, utilizing Pandas' [to_sql method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_sql.html) (latest version of Pandas is required to utilize `method=\"multi\"` fast load parameter).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close Redshift connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to Postgres\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(f\"host={config.get('POSTGRES','host')} dbname={config.get('POSTGRES','dbname')} user={config.get('POSTGRES','user')} password={config.get('POSTGRES','password')} port={config.get('POSTGRES','port')}\")\n",
    "conn.set_session(autocommit=True, readonly=False)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load segments to Postgres\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(f\"postgresql://{config.get('POSTGRES','user')}:{config.get('POSTGRES','password')}@{config.get('POSTGRES','host')}:{config.get('POSTGRES','port')}/{config.get('POSTGRES','dbname')}\")\n",
    "\n",
    "dates_segment2016df.to_sql('dates_segment2016', engine, method=\"multi\", index=False)\n",
    "dates_segment2017df.to_sql('dates_segment2017', engine, method=\"multi\", index=False)\n",
    "dates_segment2018df.to_sql('dates_segment2018', engine, method=\"multi\", index=False)\n",
    "\n",
    "location_segment2016df.to_sql('location_segment2016', engine, method=\"multi\", index=False)\n",
    "location_segment2017df.to_sql('location_segment2017', engine, method=\"multi\", index=False)\n",
    "location_segment2018df.to_sql('location_segment2018', engine, method=\"multi\", index=False)\n",
    "\n",
    "cars_segment2016df.to_sql('cars_segment2016', engine, method=\"multi\", index=False)\n",
    "cars_segment2017df.to_sql('cars_segment2017', engine, method=\"multi\", index=False)\n",
    "cars_segment2018df.to_sql('cars_segment2018', engine, method=\"multi\", index=False)\n",
    "\n",
    "non_motorists_segment2016df.to_sql('non_motorists_segment2016', engine, method=\"multi\", index=False)\n",
    "non_motorists_segment2017df.to_sql('non_motorists_segment2017', engine, method=\"multi\", index=False)\n",
    "non_motorists_segment2018df.to_sql('non_motorists_segment2018', engine, method=\"multi\", index=False)\n",
    "\n",
    "accident_segment2016df.to_sql('accident_segment2016', engine, method=\"multi\", index=False)\n",
    "accident_segment2017df.to_sql('accident_segment2017', engine, method=\"multi\", index=False)\n",
    "accident_segment2018df.to_sql('accident_segment2018', engine, method=\"multi\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now perform our pivot process on the `cars_segment` and `non_motorists_segment`:\n",
    "\n",
    "##### Disclaimer: Because pivoting creates null values in car_id and nm_id columns 2,3,4, float column type must be used to accomodate them. For clairty and practicality of future joins, we will use floats for all `car_id`s and `nm_id`s; we will also return to `cars` and `non_motorists` tables later to fix the columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install tablefunc module to access crosstab function\n",
    "create_ct = \"CREATE EXTENSION tablefunc;\"\n",
    "cur.execute(create_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert car_id and nm_id to floats\n",
    "for i in ['cars_segment2016', 'cars_segment2017', 'cars_segment2018']:\n",
    "    alter_column = f\"\"\"ALTER TABLE {i} ALTER COLUMN car_id TYPE numeric\"\"\"\n",
    "    cur.execute(alter_column)\n",
    "\n",
    "for i in ['non_motorists_segment2016', 'non_motorists_segment2017', 'non_motorists_segment2018']:\n",
    "    alter_column = f\"\"\"ALTER TABLE {i} ALTER COLUMN nm_id TYPE numeric\"\"\"\n",
    "    cur.execute(alter_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['cars_segment2016', 'cars_segment2017', 'cars_segment2018']:\n",
    "    cs_pivot_drop = f\"\"\"DROP TABLE IF EXISTS {i}ct\"\"\"\n",
    "    cs_pivot_create = f\"\"\"CREATE TABLE IF NOT EXISTS {i}ct(case_id int, car_id1 numeric, car_id2 numeric, car_id3 numeric, \n",
    "                                                           car_id4 numeric)\"\"\"  \n",
    "    cs_pivot_insert = f\"\"\"INSERT INTO {i}ct\n",
    "                          SELECT * \n",
    "                          FROM crosstab('SELECT * \n",
    "                                         FROM {i}\n",
    "                                         ORDER BY 1,2') \n",
    "                          AS {i}(case_id bigint, car_id1 numeric, car_id2 numeric, car_id3 numeric, car_id4 numeric);\"\"\"\n",
    "    cur.execute(cs_pivot_drop)\n",
    "    cur.execute(cs_pivot_create)\n",
    "    cur.execute(cs_pivot_insert)\n",
    "\n",
    "for i in ['non_motorists_segment2016', 'non_motorists_segment2017', 'non_motorists_segment2018']:\n",
    "    nms_pivot_drop = f\"\"\"DROP TABLE IF EXISTS {i}ct\"\"\"\n",
    "    nms_pivot_create = f\"\"\"CREATE TABLE IF NOT EXISTS {i}ct(case_id int, nm_id1 numeric, nm_id2 numeric, nm_id3 numeric, \n",
    "                                                            nm_id4 numeric)\"\"\" \n",
    "    nms_pivot_insert = f\"\"\"INSERT INTO {i}ct\n",
    "                           SELECT * \n",
    "                           FROM crosstab('SELECT * \n",
    "                                          FROM {i}\n",
    "                                          ORDER BY 1,2') \n",
    "                           AS {i}(case_id bigint, nm_id1 numeric, nm_id2 numeric, bignm_id3 numeric, nm_id4 numeric);\"\"\"\n",
    "    cur.execute(nms_pivot_drop)\n",
    "    cur.execute(nms_pivot_create)\n",
    "    cur.execute(nms_pivot_insert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then join all the segments and load the crosstab products into the `crashes` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create crashes table in Postgres\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    crashes_drop = f\"DROP table IF EXISTS crashes{i}\"\n",
    "    crashes_create = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS crashes{i}\n",
    "    (case_id int, date_id int, loc_id int, car_id1 numeric, car_id2 numeric, car_id3 numeric, car_id4 numeric, \n",
    "    nm_id1 numeric, nm_id2 numeric, nm_id3 numeric, nm_id4 numeric, fatalities int)\n",
    "    \"\"\"\n",
    "    cur.execute(crashes_drop)\n",
    "    cur.execute(crashes_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join and load\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    crashes_insert = f\"\"\"\n",
    "    INSERT INTO crashes{i}\n",
    "    SELECT a.st_case,\n",
    "           d.date_id,\n",
    "           l.loc_id,\n",
    "           c.car_id1, \n",
    "           c.car_id2,\n",
    "           c.car_id3,\n",
    "           c.car_id4,\n",
    "           nm.nm_id1,\n",
    "           nm.nm_id2,\n",
    "           nm.nm_id3,\n",
    "           nm.nm_id4,\n",
    "           a.fatals\n",
    "    FROM accident_segment{i} a\n",
    "    JOIN dates_segment{i} d\n",
    "    ON a.st_case = d.case_id\n",
    "    JOIN location_segment{i} l\n",
    "    ON a.st_case = l.case_id\n",
    "    JOIN cars_segment{i}ct c\n",
    "    ON a.st_case = c.case_id\n",
    "    JOIN non_motorists_segment{i}ct nm\n",
    "    ON a.st_case = nm.case_id\n",
    "    \"\"\"\n",
    "    cur.execute(crashes_insert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the `crashes` table will be retrieved from Postgres to the Jupyter Notebook API and saved, then loaded to Redshift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract to API\n",
    "cq = \"\"\" \n",
    "SELECT *\n",
    "FROM crashes{}\n",
    "\"\"\"\n",
    "crashes2016df = pd.read_sql_query(cq.format('2016'), conn)\n",
    "crashes2017df = pd.read_sql_query(cq.format('2017'), conn)\n",
    "crashes2018df = pd.read_sql_query(cq.format('2018'), conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save locally and to S3\n",
    "crashes2016df.to_csv (\"cleaned_data/crashes/2016/crashes2016c.csv\", index = None, header=True)\n",
    "crashes2017df.to_csv (\"cleaned_data/crashes/2017/crashes2017c.csv\", index = None, header=True)\n",
    "crashes2018df.to_csv (\"cleaned_data/crashes/2018/crashes2018c.csv\", index = None, header=True)\n",
    "\n",
    "for i in ['cleaned_data/crashes/2016/crashes2016c.csv', 'cleaned_data/crashes/2017/crashes2017c.csv', 'cleaned_data/crashes/2018/crashes2018c.csv']:\n",
    "    s3_client.upload_file(f'{i}', config.get('S3','bucket'), f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disconnect from Postgres and reconnect to Redshift\n",
    "\n",
    "conn.close()\n",
    "\n",
    "conn = psycopg2.connect(f\"host={config.get('REDSHIFT','host')} dbname={config.get('REDSHIFT','dbname')} user={config.get('REDSHIFT','user')} password={config.get('REDSHIFT','password')} port={config.get('REDSHIFT','port')}\")\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create crashes table\n",
    "for i in [\"2016\", \"2017\", \"2018\"]:\n",
    "    crashes_drop = f\"DROP table IF EXISTS crashes{i}\"\n",
    "    crashes_create = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS crashes{i}\n",
    "    (case_id int, date_id int, loc_id int, car_id1 numeric, car_id2 numeric, car_id3 numeric, car_id4 numeric, \n",
    "    nm_id1 numeric, nm_id2 numeric, nm_id3 numeric, nm_id4 numeric, fatalities int)\n",
    "    \"\"\"\n",
    "    cur.execute(crashes_drop)\n",
    "    cur.execute(crashes_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load crashes table\n",
    "for i in ['crashes2016', 'crashes2017', 'crashes2018']:\n",
    "    load_crashes_query = f\"\"\"\n",
    "    COPY {i}\n",
    "    FROM 's3://{config.get('S3','bucket')}/cleaned_data/{i[:-4]}/{i[-4:]}'\n",
    "    ACCESS_KEY_ID '{config.get('AWS','aws_access_key_id')}'\n",
    "    SECRET_ACCESS_KEY '{config.get('AWS','aws_secret_access_key')}'\n",
    "    IGNOREHEADER 1\n",
    "    DELIMITER ','\n",
    "    \"\"\"\n",
    "    cur.execute(load_crashes_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we finish by fixing our `car_id` and `nm_id` columns in `cars` and `non_motorists` tables, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cars\n",
    "for i in ['2016', '2017','2018']:\n",
    "    fix_cars = f\"\"\"\n",
    "                    BEGIN TRANSACTION;\n",
    "\n",
    "                    ALTER TABLE cars{i} RENAME TO cars{i}old;\n",
    "                    CREATE TABLE cars{i} (car_id numeric, case_id int, make int, model int, mod_year int, damage text, \n",
    "                                          dr_age int, dr_sex text, dr_injury text, dr_impair text);\n",
    "                    INSERT INTO cars{i}\n",
    "                    SELECT CAST(car_id as numeric),\n",
    "                           case_id,\n",
    "                           make,\n",
    "                           model,\n",
    "                           mod_year,\n",
    "                           damage,\n",
    "                           dr_age,\n",
    "                           dr_sex,\n",
    "                           dr_injury,\n",
    "                           dr_impair\n",
    "                    FROM cars{i}OLD;\n",
    "                    DROP TABLE cars{i}OLD;\n",
    "\n",
    "                    END TRANSACTION;\n",
    "                \"\"\"\n",
    "    cur.execute(fix_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non_motorists\n",
    "for i in ['2016', '2017','2018']:\n",
    "    fix_nm = f\"\"\"\n",
    "                    BEGIN TRANSACTION;\n",
    "\n",
    "                    ALTER TABLE non_motorists{i} RENAME TO non_motorists{i}old;\n",
    "                    CREATE TABLE non_motorists{i} (nm_id numeric, case_id int, nm_type text, nm_age int, nm_sex text, \n",
    "                                                   nm_injury text, nm_impair text);\n",
    "                    INSERT INTO non_motorists{i}\n",
    "                    SELECT CAST(nm_id as numeric),\n",
    "                           case_id,\n",
    "                           nm_type, \n",
    "                           nm_age, \n",
    "                           nm_sex, \n",
    "                           nm_injury, \n",
    "                           nm_impair\n",
    "                    FROM non_motorists{i}OLD;\n",
    "                    DROP TABLE non_motorists{i}OLD;\n",
    "\n",
    "                    END TRANSACTION;\n",
    "                \"\"\"\n",
    "    cur.execute(fix_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "\n",
    "Now that all the tables have been loaded on to Redshift, we will execute data quality checks. We will perform the following checks:\n",
    "\n",
    "* Count: Confirm that correct numbers of rows have been inserted. \n",
    "* Datatype: Confirm that each column does have the correct datatype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   expected_rows  inserted_rows count_check_dates2016\n",
      "0          34748          34748                  PASS\n",
      "   expected_rows  inserted_rows count_check_dates2017\n",
      "0          34560          34560                  PASS\n",
      "   expected_rows  inserted_rows count_check_dates2018\n",
      "0          33654          33654                  PASS\n"
     ]
    }
   ],
   "source": [
    "#dates\n",
    "for i in ['2016', '2017', '2018']:\n",
    "    cc = f\"\"\"SELECT COUNT(a.st_case) AS expected_rows, \n",
    "                    COUNT(d.case_id) AS inserted_rows,\n",
    "                    CASE WHEN expected_rows = inserted_rows THEN 'PASS'\n",
    "                         WHEN expected_rows != inserted_rows THEN 'FAIL'\n",
    "                         END AS count_check_dates{i}\n",
    "             FROM accident{i} a\n",
    "             JOIN dates{i} d\n",
    "             ON a.st_case = d.case_id\n",
    "      \"\"\"\n",
    "    print(pd.read_sql_query(cc, conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   expected_rows  inserted_rows count_check_location2016\n",
      "0          17118          17118                     PASS\n",
      "   expected_rows  inserted_rows count_check_location2017\n",
      "0          17324          17324                     PASS\n",
      "   expected_rows  inserted_rows count_check_location2018\n",
      "0          16507          16507                     PASS\n"
     ]
    }
   ],
   "source": [
    "#location\n",
    "for i in ['2016', '2017', '2018']:\n",
    "    cc = f\"\"\"SELECT COUNT(a.st_case) AS expected_rows, \n",
    "                    COUNT(l.case_id) AS inserted_rows, \n",
    "                    CASE WHEN expected_rows = inserted_rows THEN 'PASS'\n",
    "                         WHEN expected_rows != inserted_rows THEN 'FAIL'\n",
    "                         END AS count_check_location{i}\n",
    "            FROM accident{i} a\n",
    "            JOIN location{i} l\n",
    "            ON a.st_case = l.case_id\n",
    "      \"\"\"\n",
    "    print(pd.read_sql_query(cc, conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   expected_rows  inserted_rows count_check_cars2016\n",
      "0         102652         102652                 PASS\n",
      "   expected_rows  inserted_rows count_check_cars2017\n",
      "0         102995         102995                 PASS\n",
      "   expected_rows  inserted_rows count_check_cars2018\n",
      "0          99862          99862                 PASS\n"
     ]
    }
   ],
   "source": [
    "#cars\n",
    "for i in ['2016', '2017', '2018']:\n",
    "    cc = f\"\"\"SELECT COUNT(v.st_case) AS expected_rows, \n",
    "                    COUNT(c.case_id) AS inserted_rows, \n",
    "                    CASE WHEN expected_rows = inserted_rows THEN 'PASS'\n",
    "                         WHEN expected_rows != inserted_rows THEN 'FAIL'\n",
    "                         END AS count_check_cars{i}\n",
    "             FROM vehicle{i} v\n",
    "             JOIN cars{i} c\n",
    "             ON v.st_case = c.case_id\n",
    "      \"\"\"\n",
    "    print(pd.read_sql_query(cc, conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   expected_rows  inserted_rows count_check_non_motorists2016\n",
      "0          17733          17733                          PASS\n",
      "   expected_rows  inserted_rows count_check_non_motorists2017\n",
      "0          27799          27799                          PASS\n",
      "   expected_rows  inserted_rows count_check_non_motorists2018\n",
      "0          16523          16523                          PASS\n"
     ]
    }
   ],
   "source": [
    "#non_motorists \n",
    "for i in ['2016', '2017', '2018']:\n",
    "    cc = f\"\"\"SELECT COUNT(p.st_case) AS expected_rows, \n",
    "                    COUNT(nm.case_id) AS inserted_rows, \n",
    "                    CASE WHEN expected_rows = inserted_rows THEN 'PASS'\n",
    "                         WHEN expected_rows != inserted_rows THEN 'FAIL'\n",
    "                         END AS count_check_non_motorists{i}\n",
    "             FROM (SELECT *\n",
    "                   FROM person{i}\n",
    "                   WHERE veh_no = 0) p\n",
    "             JOIN non_motorists{i} nm\n",
    "             ON p.st_case = nm.case_id\n",
    "      \"\"\" \n",
    "    print(pd.read_sql_query(cc, conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   expected_rows  inserted_rows count_check_crashes2016\n",
      "0           5000           5000                    PASS\n",
      "   expected_rows  inserted_rows count_check_crashes2017\n",
      "0           4932           4932                    PASS\n",
      "   expected_rows  inserted_rows count_check_crashes2018\n",
      "0           5065           5065                    PASS\n"
     ]
    }
   ],
   "source": [
    "#crashes\n",
    "for i in ['2016', '2017', '2018']:\n",
    "    cc = f\"\"\"SELECT COUNT(a.st_case) AS expected_rows, \n",
    "                    COUNT(cr.case_id) AS inserted_rows, \n",
    "                    CASE WHEN expected_rows = inserted_rows THEN 'PASS'\n",
    "                         WHEN expected_rows != inserted_rows THEN 'FAIL'\n",
    "                         END AS count_check_crashes{i}\n",
    "             FROM accident{i} a\n",
    "             JOIN crashes{i} cr\n",
    "             ON a.st_case = cr.case_id\n",
    "      \"\"\"\n",
    "    print(pd.read_sql_query(cc, conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datatype Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    column expected_datatype actual_datatype datatype_check_dates2016\n",
      "0  date_id           integer         integer                     PASS\n",
      "1  case_id           integer         integer                     PASS\n",
      "2     year           integer         integer                     PASS\n",
      "3    month           integer         integer                     PASS\n",
      "4      day           integer         integer                     PASS\n",
      "5  weekday           integer         integer                     PASS\n",
      "6     hour           integer         integer                     PASS\n",
      "7   minute           integer         integer                     PASS\n",
      "    column expected_datatype actual_datatype datatype_check_dates2017\n",
      "0  date_id           integer         integer                     PASS\n",
      "1  case_id           integer         integer                     PASS\n",
      "2     year           integer         integer                     PASS\n",
      "3    month           integer         integer                     PASS\n",
      "4      day           integer         integer                     PASS\n",
      "5  weekday           integer         integer                     PASS\n",
      "6     hour           integer         integer                     PASS\n",
      "7   minute           integer         integer                     PASS\n",
      "    column expected_datatype actual_datatype datatype_check_dates2018\n",
      "0  date_id           integer         integer                     PASS\n",
      "1  case_id           integer         integer                     PASS\n",
      "2     year           integer         integer                     PASS\n",
      "3    month           integer         integer                     PASS\n",
      "4      day           integer         integer                     PASS\n",
      "5  weekday           integer         integer                     PASS\n",
      "6     hour           integer         integer                     PASS\n",
      "7   minute           integer         integer                     PASS\n"
     ]
    }
   ],
   "source": [
    "#dates\n",
    "for i in ['2016', '2017', '2018']:\n",
    "    dc = f\"\"\"SELECT \"column\",\n",
    "                    CASE WHEN \"column\" = 'date_id' THEN 'integer' \n",
    "                         WHEN \"column\" = 'case_id' THEN 'integer' \n",
    "                         WHEN \"column\" = 'year' THEN 'integer' \n",
    "                         WHEN \"column\" = 'month' THEN 'integer'\n",
    "                         WHEN \"column\" = 'day' THEN 'integer'\n",
    "                         WHEN \"column\" = 'weekday' THEN 'integer' \n",
    "                         WHEN \"column\" = 'hour' THEN 'integer'\n",
    "                         WHEN \"column\" = 'minute' THEN 'integer'\n",
    "                         END AS expected_datatype,\n",
    "                    type AS actual_datatype,\n",
    "                    CASE WHEN expected_datatype = actual_datatype THEN 'PASS'\n",
    "                         WHEN expected_datatype != actual_datatype THEN 'FAIL'\n",
    "                         END AS datatype_check_dates{i}\n",
    "         FROM pg_table_def\n",
    "         WHERE tablename = 'dates{i}' \n",
    "      \"\"\"\n",
    "    print(pd.read_sql_query(dc, conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      column       expected_datatype         actual_datatype  \\\n",
      "0     loc_id                 integer                 integer   \n",
      "1    case_id                 integer                 integer   \n",
      "2      state  character varying(256)  character varying(256)   \n",
      "3       city  character varying(256)  character varying(256)   \n",
      "4     county  character varying(256)  character varying(256)   \n",
      "5   latitude           numeric(18,0)           numeric(18,0)   \n",
      "6  longitude           numeric(18,0)           numeric(18,0)   \n",
      "\n",
      "  datatype_check_location2016  \n",
      "0                        PASS  \n",
      "1                        PASS  \n",
      "2                        PASS  \n",
      "3                        PASS  \n",
      "4                        PASS  \n",
      "5                        PASS  \n",
      "6                        PASS  \n",
      "      column       expected_datatype         actual_datatype  \\\n",
      "0     loc_id                 integer                 integer   \n",
      "1    case_id                 integer                 integer   \n",
      "2      state  character varying(256)  character varying(256)   \n",
      "3       city  character varying(256)  character varying(256)   \n",
      "4     county  character varying(256)  character varying(256)   \n",
      "5   latitude           numeric(18,0)           numeric(18,0)   \n",
      "6  longitude           numeric(18,0)           numeric(18,0)   \n",
      "\n",
      "  datatype_check_location2017  \n",
      "0                        PASS  \n",
      "1                        PASS  \n",
      "2                        PASS  \n",
      "3                        PASS  \n",
      "4                        PASS  \n",
      "5                        PASS  \n",
      "6                        PASS  \n",
      "      column       expected_datatype         actual_datatype  \\\n",
      "0     loc_id                 integer                 integer   \n",
      "1    case_id                 integer                 integer   \n",
      "2      state  character varying(256)  character varying(256)   \n",
      "3       city  character varying(256)  character varying(256)   \n",
      "4     county  character varying(256)  character varying(256)   \n",
      "5   latitude           numeric(18,0)           numeric(18,0)   \n",
      "6  longitude           numeric(18,0)           numeric(18,0)   \n",
      "\n",
      "  datatype_check_location2018  \n",
      "0                        PASS  \n",
      "1                        PASS  \n",
      "2                        PASS  \n",
      "3                        PASS  \n",
      "4                        PASS  \n",
      "5                        PASS  \n",
      "6                        PASS  \n"
     ]
    }
   ],
   "source": [
    "#location\n",
    "for i in ['2016', '2017', '2018']:\n",
    "    dc = f\"\"\"SELECT \"column\",\n",
    "                    CASE WHEN \"column\" = 'loc_id' THEN 'integer' \n",
    "                         WHEN \"column\" = 'case_id' THEN 'integer' \n",
    "                         WHEN \"column\" = 'state' THEN 'character varying(256)' \n",
    "                         WHEN \"column\" = 'city' THEN 'character varying(256)'\n",
    "                         WHEN \"column\" = 'county' THEN 'character varying(256)'\n",
    "                         WHEN \"column\" = 'latitude' THEN 'numeric(18,0)' \n",
    "                         WHEN \"column\" = 'longitude' THEN 'numeric(18,0)'\n",
    "                         END AS expected_datatype,\n",
    "                    type AS actual_datatype,\n",
    "                    CASE WHEN expected_datatype = actual_datatype THEN 'PASS'\n",
    "                         WHEN expected_datatype != actual_datatype THEN 'FAIL'\n",
    "                         END AS datatype_check_location{i}\n",
    "         FROM pg_table_def\n",
    "         WHERE tablename = 'location{i}' \n",
    "      \"\"\"\n",
    "    print(pd.read_sql_query(dc, conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      column       expected_datatype         actual_datatype  \\\n",
      "0     car_id           numeric(18,0)           numeric(18,0)   \n",
      "1    case_id                 integer                 integer   \n",
      "2       make                 integer                 integer   \n",
      "3      model                 integer                 integer   \n",
      "4   mod_year                 integer                 integer   \n",
      "5     damage  character varying(256)  character varying(256)   \n",
      "6     dr_age                 integer                 integer   \n",
      "7     dr_sex  character varying(256)  character varying(256)   \n",
      "8  dr_injury  character varying(256)  character varying(256)   \n",
      "9  dr_impair  character varying(256)  character varying(256)   \n",
      "\n",
      "  datatype_check_cars2016  \n",
      "0                    PASS  \n",
      "1                    PASS  \n",
      "2                    PASS  \n",
      "3                    PASS  \n",
      "4                    PASS  \n",
      "5                    PASS  \n",
      "6                    PASS  \n",
      "7                    PASS  \n",
      "8                    PASS  \n",
      "9                    PASS  \n",
      "      column       expected_datatype         actual_datatype  \\\n",
      "0     car_id           numeric(18,0)           numeric(18,0)   \n",
      "1    case_id                 integer                 integer   \n",
      "2       make                 integer                 integer   \n",
      "3      model                 integer                 integer   \n",
      "4   mod_year                 integer                 integer   \n",
      "5     damage  character varying(256)  character varying(256)   \n",
      "6     dr_age                 integer                 integer   \n",
      "7     dr_sex  character varying(256)  character varying(256)   \n",
      "8  dr_injury  character varying(256)  character varying(256)   \n",
      "9  dr_impair  character varying(256)  character varying(256)   \n",
      "\n",
      "  datatype_check_cars2017  \n",
      "0                    PASS  \n",
      "1                    PASS  \n",
      "2                    PASS  \n",
      "3                    PASS  \n",
      "4                    PASS  \n",
      "5                    PASS  \n",
      "6                    PASS  \n",
      "7                    PASS  \n",
      "8                    PASS  \n",
      "9                    PASS  \n",
      "      column       expected_datatype         actual_datatype  \\\n",
      "0     car_id           numeric(18,0)           numeric(18,0)   \n",
      "1    case_id                 integer                 integer   \n",
      "2       make                 integer                 integer   \n",
      "3      model                 integer                 integer   \n",
      "4   mod_year                 integer                 integer   \n",
      "5     damage  character varying(256)  character varying(256)   \n",
      "6     dr_age                 integer                 integer   \n",
      "7     dr_sex  character varying(256)  character varying(256)   \n",
      "8  dr_injury  character varying(256)  character varying(256)   \n",
      "9  dr_impair  character varying(256)  character varying(256)   \n",
      "\n",
      "  datatype_check_cars2018  \n",
      "0                    PASS  \n",
      "1                    PASS  \n",
      "2                    PASS  \n",
      "3                    PASS  \n",
      "4                    PASS  \n",
      "5                    PASS  \n",
      "6                    PASS  \n",
      "7                    PASS  \n",
      "8                    PASS  \n",
      "9                    PASS  \n"
     ]
    }
   ],
   "source": [
    "#cars\n",
    "for i in ['2016', '2017', '2018']:\n",
    "    dc = f\"\"\"SELECT \"column\",\n",
    "                    CASE WHEN \"column\" = 'car_id' THEN 'numeric(18,0)' \n",
    "                         WHEN \"column\" = 'case_id' THEN 'integer' \n",
    "                         WHEN \"column\" = 'make' THEN 'integer' \n",
    "                         WHEN \"column\" = 'model' THEN 'integer'\n",
    "                         WHEN \"column\" = 'mod_year' THEN 'integer'\n",
    "                         WHEN \"column\" = 'damage' THEN 'character varying(256)' \n",
    "                         WHEN \"column\" = 'dr_age' THEN 'integer'\n",
    "                         WHEN \"column\" = 'dr_sex' THEN 'character varying(256)'\n",
    "                         WHEN \"column\" = 'dr_injury' THEN 'character varying(256)'\n",
    "                         WHEN \"column\" = 'dr_impair' THEN 'character varying(256)'\n",
    "                         END AS expected_datatype,\n",
    "                    type AS actual_datatype,\n",
    "                    CASE WHEN expected_datatype = actual_datatype THEN 'PASS'\n",
    "                         WHEN expected_datatype != actual_datatype THEN 'FAIL'\n",
    "                         END AS datatype_check_cars{i}\n",
    "         FROM pg_table_def\n",
    "         WHERE tablename = 'cars{i}' \n",
    "      \"\"\"\n",
    "    print(pd.read_sql_query(dc, conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      column       expected_datatype         actual_datatype  \\\n",
      "0      nm_id           numeric(18,0)           numeric(18,0)   \n",
      "1    case_id                 integer                 integer   \n",
      "2    nm_type  character varying(256)  character varying(256)   \n",
      "3     nm_age                 integer                 integer   \n",
      "4     nm_sex  character varying(256)  character varying(256)   \n",
      "5  nm_injury  character varying(256)  character varying(256)   \n",
      "6  nm_impair  character varying(256)  character varying(256)   \n",
      "\n",
      "  datatype_check_non_motorists2016  \n",
      "0                             PASS  \n",
      "1                             PASS  \n",
      "2                             PASS  \n",
      "3                             PASS  \n",
      "4                             PASS  \n",
      "5                             PASS  \n",
      "6                             PASS  \n",
      "      column       expected_datatype         actual_datatype  \\\n",
      "0      nm_id           numeric(18,0)           numeric(18,0)   \n",
      "1    case_id                 integer                 integer   \n",
      "2    nm_type  character varying(256)  character varying(256)   \n",
      "3     nm_age                 integer                 integer   \n",
      "4     nm_sex  character varying(256)  character varying(256)   \n",
      "5  nm_injury  character varying(256)  character varying(256)   \n",
      "6  nm_impair  character varying(256)  character varying(256)   \n",
      "\n",
      "  datatype_check_non_motorists2017  \n",
      "0                             PASS  \n",
      "1                             PASS  \n",
      "2                             PASS  \n",
      "3                             PASS  \n",
      "4                             PASS  \n",
      "5                             PASS  \n",
      "6                             PASS  \n",
      "      column       expected_datatype         actual_datatype  \\\n",
      "0      nm_id           numeric(18,0)           numeric(18,0)   \n",
      "1    case_id                 integer                 integer   \n",
      "2    nm_type  character varying(256)  character varying(256)   \n",
      "3     nm_age                 integer                 integer   \n",
      "4     nm_sex  character varying(256)  character varying(256)   \n",
      "5  nm_injury  character varying(256)  character varying(256)   \n",
      "6  nm_impair  character varying(256)  character varying(256)   \n",
      "\n",
      "  datatype_check_non_motorists2018  \n",
      "0                             PASS  \n",
      "1                             PASS  \n",
      "2                             PASS  \n",
      "3                             PASS  \n",
      "4                             PASS  \n",
      "5                             PASS  \n",
      "6                             PASS  \n"
     ]
    }
   ],
   "source": [
    "#non_motorists\n",
    "for i in ['2016', '2017', '2018']:\n",
    "    dc = f\"\"\"SELECT \"column\",\n",
    "                    CASE WHEN \"column\" = 'nm_id' THEN 'numeric(18,0)' \n",
    "                         WHEN \"column\" = 'case_id' THEN 'integer' \n",
    "                         WHEN \"column\" = 'nm_type' THEN 'character varying(256)' \n",
    "                         WHEN \"column\" = 'nm_age' THEN 'integer'\n",
    "                         WHEN \"column\" = 'nm_sex' THEN 'character varying(256)'\n",
    "                         WHEN \"column\" = 'nm_injury' THEN 'character varying(256)' \n",
    "                         WHEN \"column\" = 'nm_impair' THEN 'character varying(256)'\n",
    "                         END AS expected_datatype,\n",
    "                    type AS actual_datatype,\n",
    "                    CASE WHEN expected_datatype = actual_datatype THEN 'PASS'\n",
    "                         WHEN expected_datatype != actual_datatype THEN 'FAIL'\n",
    "                         END AS datatype_check_non_motorists{i}\n",
    "         FROM pg_table_def\n",
    "         WHERE tablename = 'non_motorists{i}' \n",
    "      \"\"\"\n",
    "\n",
    "    print(pd.read_sql_query(dc, conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        column expected_datatype actual_datatype datatype_check_crashes2016\n",
      "0      case_id           integer         integer                       PASS\n",
      "1      date_id           integer         integer                       PASS\n",
      "2       loc_id           integer         integer                       PASS\n",
      "3      car_id1     numeric(18,0)   numeric(18,0)                       PASS\n",
      "4      car_id2     numeric(18,0)   numeric(18,0)                       PASS\n",
      "5      car_id3     numeric(18,0)   numeric(18,0)                       PASS\n",
      "6      car_id4     numeric(18,0)   numeric(18,0)                       PASS\n",
      "7       nm_id1     numeric(18,0)   numeric(18,0)                       PASS\n",
      "8       nm_id2     numeric(18,0)   numeric(18,0)                       PASS\n",
      "9       nm_id3     numeric(18,0)   numeric(18,0)                       PASS\n",
      "10      nm_id4     numeric(18,0)   numeric(18,0)                       PASS\n",
      "11  fatalities           integer         integer                       PASS\n",
      "        column expected_datatype actual_datatype datatype_check_crashes2017\n",
      "0      case_id           integer         integer                       PASS\n",
      "1      date_id           integer         integer                       PASS\n",
      "2       loc_id           integer         integer                       PASS\n",
      "3      car_id1     numeric(18,0)   numeric(18,0)                       PASS\n",
      "4      car_id2     numeric(18,0)   numeric(18,0)                       PASS\n",
      "5      car_id3     numeric(18,0)   numeric(18,0)                       PASS\n",
      "6      car_id4     numeric(18,0)   numeric(18,0)                       PASS\n",
      "7       nm_id1     numeric(18,0)   numeric(18,0)                       PASS\n",
      "8       nm_id2     numeric(18,0)   numeric(18,0)                       PASS\n",
      "9       nm_id3     numeric(18,0)   numeric(18,0)                       PASS\n",
      "10      nm_id4     numeric(18,0)   numeric(18,0)                       PASS\n",
      "11  fatalities           integer         integer                       PASS\n",
      "        column expected_datatype actual_datatype datatype_check_crashes2018\n",
      "0      case_id           integer         integer                       PASS\n",
      "1      date_id           integer         integer                       PASS\n",
      "2       loc_id           integer         integer                       PASS\n",
      "3      car_id1     numeric(18,0)   numeric(18,0)                       PASS\n",
      "4      car_id2     numeric(18,0)   numeric(18,0)                       PASS\n",
      "5      car_id3     numeric(18,0)   numeric(18,0)                       PASS\n",
      "6      car_id4     numeric(18,0)   numeric(18,0)                       PASS\n",
      "7       nm_id1     numeric(18,0)   numeric(18,0)                       PASS\n",
      "8       nm_id2     numeric(18,0)   numeric(18,0)                       PASS\n",
      "9       nm_id3     numeric(18,0)   numeric(18,0)                       PASS\n",
      "10      nm_id4     numeric(18,0)   numeric(18,0)                       PASS\n",
      "11  fatalities           integer         integer                       PASS\n"
     ]
    }
   ],
   "source": [
    "#crashes\n",
    "for i in ['2016', '2017', '2018']:\n",
    "    dc = f\"\"\"SELECT \"column\",\n",
    "                    CASE WHEN \"column\" = 'case_id' THEN 'integer' \n",
    "                         WHEN \"column\" = 'date_id' THEN 'integer' \n",
    "                         WHEN \"column\" = 'loc_id' THEN 'integer'\n",
    "                         WHEN \"column\" = 'car_id1' THEN 'numeric(18,0)'\n",
    "                         WHEN \"column\" = 'car_id2' THEN 'numeric(18,0)' \n",
    "                         WHEN \"column\" = 'car_id3' THEN 'numeric(18,0)'\n",
    "                         WHEN \"column\" = 'car_id4' THEN 'numeric(18,0)'\n",
    "                         WHEN \"column\" = 'nm_id1' THEN 'numeric(18,0)'\n",
    "                         WHEN \"column\" = 'nm_id2' THEN 'numeric(18,0)'\n",
    "                         WHEN \"column\" = 'nm_id3' THEN 'numeric(18,0)'\n",
    "                         WHEN \"column\" = 'nm_id4' THEN 'numeric(18,0)'\n",
    "                         WHEN \"column\" = 'fatalities' THEN 'integer'\n",
    "                         END AS expected_datatype,\n",
    "                    type AS actual_datatype,\n",
    "                    CASE WHEN expected_datatype = actual_datatype THEN 'PASS'\n",
    "                         WHEN expected_datatype != actual_datatype THEN 'FAIL'\n",
    "                         END AS datatype_check_crashes{i}\n",
    "         FROM pg_table_def\n",
    "         WHERE tablename = 'crashes{i}' \n",
    "      \"\"\"\n",
    "    print(pd.read_sql_query(dc, conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "**Fact Table**\n",
    "\n",
    "1. **crashes**\n",
    "\n",
    "    - case_id: accident case identifier - `st_case` column from the `accident` table\n",
    "    - date_id: accident date identifier - autoincrement column from the `dates` table  \n",
    "    - loc_id: accident location identifier - autoincrement column from the `location` table \n",
    "    - car_id1: car1/driver identifier - autoincrement column from the `cars` table    \n",
    "    - car_id2: car2/driver identifier - autoincrement column from the `cars` table \n",
    "    - car_id3: car3/driver identifier - autoincrement column from the `cars` table \n",
    "    - car_id4: car4/driver identifier - autoincrement column from the `cars` table  \n",
    "    - nm_id1: non-motorist1 identifier - autoincrement column from the `nmimpair` table   \n",
    "    - nm_id2: non-motorist2 identifier - autoincrement column from the `nmimpair` table  \n",
    "    - nm_id3: non-motorist3 identifier - autoincrement column from the `nmimpair` table  \n",
    "    - nm_id4: non-motorist4 identifier - autoincrement column from the `nmimpair` table \n",
    "    - fatalities: number of deaths in the accident - `fatals` column from the `accident` table.  \n",
    "\n",
    "**Dimension Tables**\n",
    "\n",
    "2. **dates**\n",
    "    - date_id: accident date identifier - autoincremented during `accident` table data extraction   \n",
    "    - case_id: accident case identifier - `st_case` column from the `accident` table\n",
    "    - year: year of the accident - `year` column from the `accident` table\n",
    "    - month: month of the accident - `month` column from the `accident` table\n",
    "    - day: day of the accident - `day` column from the `accident` table \n",
    "    - weekday: weekday of the accident - `day_week` column from the `accident` table \n",
    "    - hour: hour of the accident - `hour` column from the accident table \n",
    "    - minute: minute of the accident - `minute` column from the accident table  \n",
    "\n",
    "3. **location**\n",
    "    - loc_id: accident location identifier - autoincremented during `accident`/`glc` table data extraction  \n",
    "    - case_id: accident case identifier - `st_case` column from the `accident` table\n",
    "    - state: state of the accident location - `state_name` column from the `glc` table   \n",
    "    - city: city of the accident location - `city_name` column from the `glc` table \n",
    "    - county: county of the accident location - `county_name` column from the `glc` table \n",
    "    - latitude: latitude coordinate of the accident location - `latitude` column from the `accident` table   \n",
    "    - longitude: longitude coordinate of the accident location - `longitud` column from the `accident` table  \n",
    "    \n",
    "4. **cars**\n",
    "    - car_id: car/driver identifier - autoincremented during `vehicle`/`person` table data extraction  \n",
    "    - case_id: accident case identifier - `st_case` column from the `accident` table  \n",
    "    - make: make of the vehicle - `make` column from the `vehicle` table  \n",
    "    - model: model of the vehicle - `model` column from the `vehicle` table     \n",
    "    - mod_year: model year of the vehicle - `mod_year` column from the `vehicle` table   \n",
    "    - damage: damage level of the vehicle - `deformed` column from the `vehicle` table      \n",
    "    - dr_age: vehicle driver age - `age` column from the `person` table  \n",
    "    - dr_sex: vehicle driver sex - `sex` column from the `person` table \n",
    "    - dr_injury: vehicle driver injury level - `inj_sec` column from the `person` table   \n",
    "    - dr_impair: vehicle driver impairment - `drimpair` column from the `drimpair` column\n",
    "    \n",
    "5. **non_motorists**\n",
    "    - nm_id: non-motorist identifier - autoincremented during `person`/`nmimpair` table data extraction  \n",
    "    - case_id: accident case identifier - `st_case` column from the `accident` table \n",
    "    - nm_type: non-motorst type - `per_typ` column from the `person` table   \n",
    "    - nm_age: non-motorist age - `age` column from the `person` table \n",
    "    - nm_sex: non-motorist sex - `sex` column from the `person` table  \n",
    "    - nm_injury: non-motorist injury level - `inj_sec` column from the `person` table    \n",
    "    - nm_impair: non-motorist - `nmimpair` column from the `nmimpair` table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clearly state the rationale for the choice of tools and technologies for the project:\n",
    "```\n",
    "Redshift: Fast speed of copies and queries provided by MPP(Massively Parallel Processing) architecture, high compatibility and ease with S3 storage for data import and export. \n",
    "\n",
    "S3: High compatibility with Redshift, high capacity storage, ease of data transfer.\n",
    "\n",
    "Postgres: Pivot functionality (crosstab function) from tablefunc module, same stack lineage as Redshift.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Propose how often the data should be updated and why:\n",
    "```\n",
    "If under study, the data should be updated annually - FARS publishes crash data annually.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write a description of how you would approach the problem differently under the following scenarios:\n",
    "\n",
    "##### The data was increased by 100x.**\n",
    "```\n",
    "1. Increase the number of nodes, processing power, and memory.\n",
    "\n",
    "2. Designate distyle, distkeys, and sortkeys to optimize joins and reads.\n",
    "```   \n",
    "##### The data populates a dashboard that must be updated on a daily basis by 7am every day.**\n",
    "```\n",
    "ETL script will be set up on Airflow to daily schedule for 7AM.\n",
    "```\n",
    "##### The database needed to be accessed by 100+ people.\n",
    "```\n",
    "Ideally, all the requesters will be registered as AWS IAM users, but otherwise the requested tables will be exported and sent out as CSV/XLSX files.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
